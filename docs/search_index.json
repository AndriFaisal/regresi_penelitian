[["index.html", "Regresi Untuk Penelitian Bab1 About 1.1 Usage 1.2 Render book 1.3 Preview book", " Regresi Untuk Penelitian andri Faisal 2025-02-10 Bab1 About This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports; for example, a math equation \\(a^2 + b^2 = c^2\\). 1.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: # A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ## A short section or ### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. 1.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. 1.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book”, or from the R console: bookdown::serve_book() "],["pendahuluan.html", "Bab2 Pendahuluan", " Bab2 Pendahuluan Dalam waktu penelitian kita membutuhakan hal sesuatua yang menyeelsaikan permasalahan kita. Manusia mempunyai naluri untuk menyelesaikan masalah sendiri. Dahulu banyak sekali hal yang bisa kita carikan. Hal mencari soulusi yang akan ada untuk mencari yang memudahkan hidup mereka sendiri. Ada hal yang selalu berubah itu kita tidak pungkisiri seperti itu. Kita kesulitan untuk memprediksi suatua atau beberapa hal. Dalam regresi kita akan melihat hubungan antara satu dengan variabel yang lainnya . Kita bisa memprediksi satu variabel tersebut dengan caa melihat variabel yang lain. Sifat asli manusia yang mempunyai rasa ingin tahu dan mencari faktor yang menjadi pneghubung. Kenapa sesuatua yaitu faktor independen mempunyai pengaruh. Ada beberapa pengaruh yang harus di cari untuk menerangkan hal yang lain. Dalam buku ini saya akan menyajikan pengenalan terhadap regresi itu sendiri. Regresi adalah sesuatu metode perhitungan atau kalkulasi dari covarian berhubungan antara variabel bebas dan juga variabel tak bebas. Dari nilai ini kita akan dapat menduga nilai hubungan yang erat yang diwakili dengan nilai satu sampai dengan nilai 0. Sesudah itu akan diterangkan konsep dasar statistik mengenai regresi. Kita tahu regresi adalah berbeda dnegan stataistik sebelumnya yakni stataistik deskriptif. Untuk kalkukasi regresi termasuk da;lam stataistik analisis. Dari sini seorang mulai menganalisis data yang sudah ada berita megenai hubungan antara kedua data. Sebelumnya juga ada suatau ulangan mengenai apa itu stataistik. Pengenalan regresi akan ada pada variabel. Variabel yang merupakan nilai dari kharakteristik suatu sample. Kita mendapat nilai tersebut untuk dihubungkan dengan dengan yang lain. Penulis memandang penting agar para pembaca bisa untuk memahami maksuda dari model analisis regresi tersebut. Setelah pengenalan maka masuk ke dalam regresi sederhana yang hanya memuat satu variabel independen saja. Dalam regresi sederhana , maka faktor dependen atau variabel terikat hanya terpengaruh dari satu variabel saja. Ada variabel dominan yang dapat mempengaruhi suatu faktor seperti hubungan antara penghasilan dengan kepandaian. Bisa jadi nilai kepandaian atau variabel kepandaian tersebut dapat ubtu mempengaruhi penghasilan orang. Kita membutuhkan suatau nilai yang digunakan untuk mengukur derajat dari pengaruh variable ke variabel lainnya. Heumann and Shalabih (2016) Karena hanya satu variable maka rasanya kurang untuk menghitung hanya satu variabel saja karenanya ada regresi dengan eberapa faktor independen. Faktor-faktor inilah yang diduga dengan bersama-sama turut dalam mempegaruhi variabel independen tersebut. Dengan regresi yang begitu komplek tersebut maka akan ada sejumlah asumsi. Sebelum ke asumsi namanya regresi juga mempunyai syarat yang harus dipenuhi. Appaun model analisis juga harus memenuhi syarat. Dari syarat tersebut nanti kita akan mendapatkan sautu bentuk peramalan yang sesuai atau sedikit kesalahan. Peramalan yang baik adalah peramalan yang bukan memiliki kesalahalan akan tetapi peramalan yang baik adalah yang kesalahannya sedikit. Dengan adanya asusmi linear itu akan memastikan kalau model sudah cukup untuk memenuhi kriteria peramalan yang baik. Adapun asumsi linear yang harus dipenuhi seperti multikolinearitas, autokorelasi, heteroskedatisitas dan lainnya. Dalam regresi linear juga harus mempertimbangkan asumsi normal. Data harus terdistribusi normal agar setiap bentuk pendugaan akan benar. Setelah regresi selesai maka ada evaluasi model dengan bebebrapa kriteria seperti nilai MSE dan MAE. Dengan penilaian seperti ini kita akan mengetahui ada regresi yang baik. Buku ini ditutup dengan studi kasus agar setiap pembavca dapat mempelajari kasus apa yang terjadi. Hal ini akan bisa untuk semakin mendalami maksud dari pelajaran regresi kali ini. References "],["regresi-linier-sederhana.html", "Bab3 Regresi Linier Sederhana 3.1 Keterbatasan Regresi Linear 3.2 Regresi linear dengan kategori Latihan", " Bab3 Regresi Linier Sederhana Regresi Linear Sederhana Grafik Pencar atau Scatter Graph Salah satu hal yang penting adalah ketika kita mau menduga hubungan antara variabel X dengan variabel Y yakni dengan scatter graph. Dengan gambar yang ada hubungan. Variabel Y akan kita tempatkan di bagian vertikal atau bagian yang menghadap ke atas sebaliknya dengan bagian X yang mendatar seperti horizontal. Kita memasangkan sesuai dengan pasangan nilai data tersebut X dan Y. Jangan pasang teracak agar kita bisa melihat hubungan antara keduanya. Pasangan data tersebut adalah yang termasuk dalam individu misalnya ada seorang yang mempunyai pendapatan X dengan pengeluaran Y maka nilai itu yang kita pasangkan bukan malah membuat pendapatan seorang tertentu dengan pengeluaran yang lain karena itu akan menjadi berbeda nilainya. Dari hubungan tersebut akan membentuk scatter graph. Ada sejumlah titik-titik yang menyebar atau mengumpul di sekitar grafik pencar scatter graph tersebut. Titik titik itu mewakili banyak individu yang memiliki nilai dari kedua variabel X dan Y. Banyaknya kumpulan titik atau scatter itu bergantung dari banyaknya daat tersebut. Semakin banyak jumlah data yang dibuat sampel adalah dengan dimasukkan dalam grafik tersebut. Ada beberapa hal yang dapat kita pelajari dari scatter plot seperti: 1. Pola dari titik tersebut mempunyai pola seperti cenderung mengumpul di satu tempat karena nilanya mempunyai yang sama 2. Trend. Kita dapat melihat suatu trend ketika ada satu garis yang bisa kita tarik pada titik tersebut dan kita menunjukkan ada yang bisa menunjukan garis ke atas atau bahkan tidak memiliki trend. 3. Outlier. Outlier adalah nilai yang terpencil . Ia hanya sendiri dan jauh di pinggir atau ditengah nilai-nilai yang lain karenanya disebut outlier. Outlier tentu sedikit dan ini menyebabkan data tidak normal. Regresi Linear adalah salah satu cara untuk melihat hubungan antara variabel bebas dengan variabel tidak bebas. Dalam hal ini yang mempengaruhi adalah variabel yang bebas sedangkan yang dipengaruhi adalah variabel tidak bebas. Dalam regresi hanya mengenal satu arah saja pengaruh yakni variabel bebas terhadap variabel dependen dan bukan sebaliknya. Pembatasan itu dengan tegas agar dalam mencari hubungan tidak akan ada kekeliruan. Misalnya pengaruh garam terhadap darah tinggi maka dari sini kita akan mencari hubungan antara garam dengan darah tinggi. Garamlah yang mempengaruhi tingginya tekanan darah (tensi) seseorang. Dengan alasan ilmiah dan penjelasan kalau zat garam akan meningkatkan tekanan darah tersebut. Kita tentu tidak akan menempatkan garam sebagai hal yang dependen tetapi ia adalah sesuatau yang bebas dalam hal ini karenanya ia mempengaruhi tekanan darah tinggi. Apakah ia akan menjadi faktor yang dipengaruhi. Hal itu bisa saja kalau dalam konteks yang lain misalnya kalau garam itu akan dipengaruhi oleh jumlah sinar matahari yang menerpa bumi. Regresi linear pertama kali dikenalkan oleh Galton yang menemukan adanya hubungan tinggi anak dengan tinggi orang tuanya. Ia menghitung jumlah banyaknya anak yang mempunyai dengan tinggi orang tuanya. Hal ini berkaiatan dengann keturunan atau hereditas. Galton ingin menemukan apakah ada tinggi orang tua akan mempengaruhi tinggi sang anak. Regresi linear hanya memeriksa antara hubungan variabel beas dengan variabel tidak bebas. Dalam regresi ini karena hanya ada satu maka disebut juga regresi linier sederhana (simple linear regression). Metode seperti ini dipakai seperti di ilmu bisnis, ekonomi, manajemen, komunikasi dan ilmu sosial lainnya. Dalam regresi sederhana kita akan menggambarkan hubungan dengan garis y= a+ bx. Persamaan ini dihasilkan dari perhitungan regresi terhadap dua variabel tersbeut. Untuk nilai b diperoleh dengan perhitungan jelaskan dulu mengenai perhitungan ada simpangan x dengan simpangan y dibagi dengan jumlah sample atau n. maka bisa dilihat seperti ini. Kemudian nilai a diperoleh dari nilai y rata-rata dikurangi b dikalikan dengan nilai rata-rata X dan akan kita peroleh nilai a tersebut. Bisa saja dengan menggunakan nilai perhitungan komputasi seperti Excel atau menggunakan software statistic lainnya. Dimana a = nilai intercept atau nilai konstanta b = koefisen slope atau kemiringan Nilai a adalah konstanta ini adalah nilai awal dari persamaan suatu garis persamaan regresi tersebut. Nilai ini selalu ada. Hal yang ketika terjadi nilai regresor tersebut nol maka tetap saja nilai untuk Y prediksi tetap ada. Inilah nilai yang dinamakan nilai konstanta. Terkadang nama konstanta atau alpha disebut juga intercept sedangkan Beta dinamakan juga slope parameter atau ada juga yang menamakannya parameter. Y (x=0) = a + bx Y = a + 0.x = a Nilai b ini menunjukkan kemiringan dari garis yang menunjukan hubungan antara y dengan X nilai positif berarti nilai yang menunjukkan seiringan atau hubungan yang sama-sama naik atau sama-sama turun. Ketika variabel independen mempunyai nilai yang positif maka akan merubah juga variabel dependen juga akan turut berubah menjadi positif. Bagaimana kalau nilai alpha menjadi 0 maka nilai persamaan tersebut akan memotong garis x karena tidak ada nilai alphanya. Pengaruh nilai independen bergantung dengan koefisein semakin besar maka satau perubahan akan menjadi lebih besar dengan kemiringan yang curam sekali. Misalnya Y = 0,1 + 10 X berarti pengganda dari nilai regresi tersebut akan semakin besar dengan nilai tersebut. Jika nilai kurang dari 1 namun masih nilai positif maka kemiringan tetap ke sebelah kanan jadi nilai X meningkat namun dengan peningkatan nilai tersebut semakin kecil bukan besar. Untuk nilai yang negatif menunjukkan nilai tersebut adalah saling bertolak belakang. Ketika variabel independen bergerak naik maka yang terjadi adalah variabel dependen akan menurun dan sebaliknya. Hubungan yang negatif berarti juga saling bertolak belakang dan penambahan variabel independen akan mengurangi variabel dependen tersebut. 3.1 Keterbatasan Regresi Linear Metode regresi linear adalah metode yang mendapatkan cara untuk menyelidiki hubungan antara variabel dependen dengan variabel independen. Dengan regresi tersebut kita akan mendapatkan nilai korelasi dari persamaan tersebut. Dari dua data yang disamakan tersebut kita akan mendapatkan suatu persamaan r yang mempunyai nilai -1≤r≤1 dengan perincian terhadap berikut. Nilai R Arti 0,00 - 1,99 Sangat Lemah 2,00 - 3,99 Lemah 4,00 – 5,99 Sedang 6,00 – 7,99 Kuat 8,00 -1,00 Sangat Kuat Perbedaan nilai R2 dengan koefisien Kalau koefisien menyebutkan nilai koefisen menunjukkan banyaknya atau kuatnya nilai regresi tapi hati-hati kalau hal tersebut adalah berhubungan dengan nilai r dengan nilai koefisen regresi. Baik r dan beta adalah koefisien kalau beta adalah koefisien regresi sedangkan nilai r adalah koefisein korelasi. Koefisien regresi adalah menunjukkan besarnya hubungan ada suatu hubungan yang menjadi pengganda (multiplier). Koefisien regresi juga menjadi unsur dalam persamaan regresi. Hubungan ini menunjukkan akan ada besarnya pengali saja. Sedangkan koefisen korelasi adalah nilai yang menunjukkan adanya seberapa erat hubungan tersebut. Nilai koefisein regresi menaksir atau meramal nilai Y terhadap nilai X, sedangkan kalau untuk nilai R tersebut memperkirakan keeratan hubungan. Apakah nilai tersebut mempunyai keeratan dari nilai r tersebut. Nilai dalam korelasi r dapat disimpulkan apakah ada hubungan yang kuat atau sama sekali tidak ada hubungan dalam kedua variabel tersebut. Sedangkan untuk nilai koefisein regresi maka kita akan melihat lebih jauh lagi untuk mengintrepretasikan nilai tersebut. Kita dapat menyimpulkan karena nilai dari data mentah antara variabel X dengan Y sudah berbeda. Karena nilai X dan Y mempunyai perbedaan yang besar sehingga nilai koefisiennya menjadi besar. Setiap pengaruh nilai satu independent maka akan berdampak besarnya sesuai dengan koefisen yang dihasilkan. Kertebatasan Sebagai model awal yang menunjukkan hubungan anatara variabel indpenden dan variable dependen ilmu ini adalah atau metode yang memberikan suatu pengetahunan dalam mencari hubungan tersebut. Ada beberpa variabel yang sebelumnya belum diketahui dan mungkin hanya estimasi tersbeut. Perhitungan tersebut menghasilkan suatu hubungan yang merata ataupun hubungan seberapa besar pengaruh atau pengganda tersebut dalam koefisien regresi. 3.2 Regresi linear dengan kategori Bagaimana kita bisa melakukan regresi linear dengan data kategori atau variabel independennya adalah variabel bebas. Hal itu bisa saja. Kalau kita menganggap ada perbedaan antara nilai mahasiswa dan mahasiswi maka kita akan bisa melihat perbedaan keduanya, misalnya Y=a + bx pada saat nilai untuk perempuan maka nilanya adalah alpha saja sedangkan pada saat pria ada nilai alpha plus beta. Untuk melakukan regresi kita bisa melakukan hal itu dengan hati-hati. Kedua regresi ini akan menujukkan dua perbedaan karena adanya variable dikotomi tersebut. Untuk membedakan variable mana yang satu dan mana yang nol berdasarkan kebiasaaan saja. Misalnya kebiasaan dari dalam memilih sebuah regresi kategori untuk nilai nol (0) adalah dengan jenis kelamin perempuan dan juga maka akan ada yang dapat nilai satu (1) untuk nilai untuk laki-laki. Adapun regresi dengan nilai kategori karena terjadinya perbedaan yang cukup kentara atau signfikan dari kedua kategori tersebut. Di negeri belahan Timur seperti Indonesia, kita tahu ada suatu diskriminasi upah antara pria dan wanita. Pria lebih menerima banyak upah karena hasil pekerjaan mereka lebih banyak dari para wanita. Ketika ada dua hubungan yang berbeda ini maka akan dapat menjadikan nilai persamaan regresi bisa saja menjadi bias. Latihan Jawabalah pertanyaan dengan kata yang tepat Jelaskan Konsep regresi linear menurut anda? Apa maksud Koefisen Korelasi tersebut? Apakah wajib dalam menjelaskan regresi menggunakan diagram Scatter? Anda mendapatkan pengetahuan variable bebas A dan variable tidak bebas B , bagaimana anda menenutukan garis regresi linear yang terbaik Pada setiap regresi ada residual atau sisa? Jelaskan apa maksud resisdual positif dan residual negative? Hasil output menunjukkan jika persamaan regresi adalah y=3x +5 apa arti dari persamaan regresi diatas? Dalam regresi ada namanya prediksi dan estimasi . apa perbedaan dari keduanya? Apakah heteroskedatisitas digunakan dalam regresi linier sederhana? Jelaskan? Jelaskan bagaimana variable independent dapat menjelaskan variable dependen? Jika nilai R square sekitar 0,90. Apakah artinya itu? "],["regresi-linier-berganda.html", "Bab4 Regresi Linier Berganda 4.1 Goodnes of fit 4.2 Scatter diagram Latihan 4.3 Regresi dengan Dummy", " Bab4 Regresi Linier Berganda Suatu faktor bukan dipengaruhi satu faktor saja. Seorang yang sukses bukan berasal dari ayah atau ibu yang sukses saja karena ada faktor lain. Ada anak orang kaya yang menjadi miskin karena tidak bisa mengelola harta ayahnya saja. Pada anak yang miskin ia bisa mendapatkan pendidikan dan ia meraih kekayaan yang melimpah karena keahliannya. Dalam praktik regresi linier sederhana sulit sekali dipraktekkan dan pencarian nilai tersebut hanya sederhana untuk mencari faktor yang dapat mempengaruhi faktor independen lainnya. Adanya regresi berganda karena keterbatasan regresi linear itu maksudnya yang sederhana karena tidak mungkin bahwa hal yang mempengaruhi tersebut hanya satu faktor. Sangat sederhana kalau suatu peubah dipengaruhi oleh beberapa peubah yang lainnya. Kita bisa melihat kalau nilai r square itu begitu rendah sekali karena pengaruhnya sedikit sekali. Maka kita harus mencari peubah lain yang akan mempengaruhi juga dan akan meningkatkan nilai R kuadrat. Memang tidak ada jaminan kalau peningkatan variabel atau peubah akan membuat nilai R squared akan meningkat terus. Dalam ilmu pengetahuan kita selalu mengeksplorasi dengan factor-faktor yang lain agar bisa mencari yang paling berpengaruh. Terkadang memang faktor yang diduga tidak berpengaruh maka ternyata membuatnya berpengaruh, Memang dalam regresi kita tidak tahu mana faktor yang paling yang paling berpengaruh tersebut. Sampai saat ini belum ada ukuran yang jelas mengenai hal tersebut kalu dalam penggunaan yang sama. Namun dalam penggunaan determinasi yang satu mungkin akan terlihat mana faktor yang berpengaruh. Tetapi kalau sudah tercampur terkadang sulit juga karena bias, jadi pengaruh tersebut akan berbeda? Dari matriks kita bisa melihat peramalan dalam meregresi nilai X atau beberapa variabel independen. Kita lihat perhitungannya sampai sudah rumit apalagi dengan banyak sekali variabel yang ada. Kalau regresi dua faktor hanya ada dua dimensi maka akan ada banyak dimensi. Dimensi ini akan mampu menjelaskan hubungan dari variable independent dan juga variable dependen. Adapun tujuan dari regresi adalah mencari garis persamaan yang dapat digunakan untuk meramal nilai prediksi Y atau variabel independennya sama seperti yang terjadi pada suatu masa. Terkadang data tersebut akan dapat berguna bagi banyak hal sebagai bentuk untuk menilai kebijakan yang akan diterapkan baik oleh organisasi besar dan kecil maupun juga individual yang akan menentukan kebijakan tersebut. Metode regresi linier mempunyai arti adalah untuk mencari hubungan satu variabel tidak bebas atau dependen terhadap beberapa variabel bebas lainnya. Sama halnya regresi sederhana, dalam regresi linier berganda kita akan menguji apakah beberapa variabel bebas akan dapat mempengaruhi dari variabel tidak bebas tersebut. Hasil dari regresi adalah persamaan regresi yang terdiri dari nilai Y terhadap nilai X dengan nilai koefisien seperti nilai variabel satu, variabel dua, dan selanjutnya. Nama dari hasil ini disebut juga persamaan regresi dan juga namanya adalah model regresi. Jika sudah mempunyai masalah dan ingin mengeksplore variabel atau peubah apa saja yang dapat digunakan untuk regresi maka kita dapat melakukan hal seperti ini. Anda harus tahu bahwa variabel yang akan anda cari adalah variabel yang benar-benar berpengaruh. Kalau variabel asal kita sambungkan saja maka kita tidak akan mendapatkan hal yang seperti harapan kita. Kita mengharapkan akan mendapatkan sesuatu yang baik. Hal pertama yang kita bisa lakukan adalah mengumpulkan data yang sesuai dengan tujuan penelitian atau variabel yang kita selidiki. Semuanya harus terkumpul. Semua yang akan dapat kita olah ke dalam regresi tersebut. Penting untuk menata data tersebut dan mengorganisasikan data tersebut. Sebelumnya kita lihat terlebih dulu di tabel apakah ada data outlier. Mungkin agak sulit sekali kalau kita mengandalkan tabel untuk mencari outlier. Setelah itu kita mengeksplorasi data analisis. Sebelum regresi ini bisa dilakukan bagi yang berpengalaman dari grafik akan dapat menduga apakah semua ini akan menjadi nilai estimasi yang baik atau tidak? Justru awal ini adalah mendeteksi ada kemungkinan kita akan melihat adanya hal yang tidak sesuai dengan data yang hendak kita regresi. Setelah itu kita bisa melihat adanya outliers. Data di grafik tersebut maka kita akan melihat adanya outlier yang ada. Penting mempertimbangkan adanya outlier ini. Outlier adalah salah satu nilai yang berbeda dari kebanyakan rata-rata. Nilai dari outlier dapat membuat hasil dari model regresi bias. Kita harus memastikan data yang kita dapatkan adalah data yang obyektif dan memenuhi syarat. Terkadang kita mengumpulkan data yang salah. Apalagi sampai menggunakan data yang salah ini menjadi permasalahan tersendiri. Setelah itu lakukan regresi untuk menghitung atau mengkalkulasi nilai dari persamaan regresi tersebut. Kita akan mendapatkan nilai R kuadrat atau yang dikenal dengan R Square tersebut. Nilai R2 akan mencapai sekitar 100% namun kemungkinan itu tidak ada karena kalau ada yang 100% maka patut kita curigai. Kemudian kita akan mencari nilai F tersebut yang sudah dihitung. Nilai ini adalah nilai signifikasi dari model yang kita buat. Setelah itu kita bisa untuk menilai dari variabel yang sesuai dengan nilai signifikasi. Tidak semua yang akan ada akan ada maka akan membuat semuanya signifikan karena ada saja yang hasilmya berbeda sesuai dengan data yang ada. Terakhir kita harus melihat juga asumsi model. Kita akan memastikan nilai dari persamaan regresi sudah “benar”. Hasil regresi itu tidak bisa dikatakan benar atau salah karena semuanya ada perhitungannya. 4.1 Goodnes of fit Untuk mendapatkan nilai yang paling baik adalah hal yang diinginkan. Tentu tidak memaksakan sesuatu hal yang akan menjadikan sesuatunya tidak benar atau tidak shahih dan valid. Kita dapat memeriksa nilai dari residu yang merupakan nilai Y aktual dengan Y prediksi atau sering disebut Y topi. Nilai ini merupakan nilai dari total semua residu. Sedangkan di sisi lain adalah kita menilai nilai Y dengan nilai y rata-rata dari variabel Y tersebut yang bisa jadi akan nilainya besar. Kemudian kita juga memperlihatkan nilai selisih antara Variabel Y dengan regrsi dalam nilai tersebut nilai SST yang besar sangat diharapkan menandakan nilai yang baik juga. Kemudian ada juga Nilai SSE atau nilai Sum Square Explained adalah nilai yang paling diharapkan tinggi. Ini adalah selisih nilai y aktual dengan nilai y rata-rata. Sedangkan nilai dari SSR adalah sum square dari residual dan nilai ini adalah nilai y prediksi dengan y aktual. Sum Square Total = SST = SSR + SSE Dari nilai ini kita akan memperoleh nilai R squared atau R kuadrat yang rumusnya adalah SSE/SST. Oleh karena itu yang diharapkan adalah nilai R2 besar sekali. Karena semakin nilai itu besar sekali akan menunjukkan bahwa ada hubungan yang mempunyai porsi besar sekali. Kita juga harus bisa membandingkan dengan nilai adjusted R square yang membandingkan dengan berbagai variabel atau variabel yang lebih dari satu. Cara Adjusted R square ini adalah cara yang lebih konservatif dalam menjelaskan kesesuaian (fit) model. Adapun rumus dari adjusted R Square adalah sebagai berikut ini: Adjusted R2 = 1-[(1-R2)*(n-1)/(n-p-1)] Nilai ini adalah jumlah obesravsi atau jumlah data yang dilibatkan dalam regresi. Dengan demikian nilai R square adjusted itu lebih digunakan pada waktu regresi terhadapa variable ini lebih dari dua variable bebas. Hal ini ada seperti penyesuaian dengan niai R2 tersebut. Nilai yang paling penting adalah nilai F. Nilai yang diperoleh dari nilai ANOVA ini menunjukkan kesesuaian model (fit of model). Kalau nilai dari F signifikan ini lebih kecil dari 0,05 dalam nilai ini adalah nilai yang baik. Kalau sebaliknya nilai peluang (probability value) adalah lebih besar maka tidak diterima model tersebut. Ada yang menjadi masalah dalam model tersebut. Itu yang dapat kita ketahui. Kalau model tersebut mungkin kita pikirkan model yang lain yang dapat kita jadikan model yang baru tersebut. Setelah yakin bahwa model tersebut sah kita melihat beberapa variable independent yang diduga mempengaruhi variable dependen tersebut. Kita melihat nilai t yang ada pada bagian setiap variable yang ada. Kalau nilai t hitung dalam hal ini t hitung yang dikalkulasi oleh software. Nilai t itu mempunyai nilai mutlak yang lebih besar daripada nilai table IthitungI &gt; IttabelI. Nilai dalam kurung menunjukan nilai mutlak dari t. Ketika nilai t hitung positif maka nilai yang paling besar juga akan menjadi niai yang paling besar. Kalau nilai negatf maka nilai tersebut nilai yang paling besar. Sejatinya nilai minus yang paling besar adalah nilai yang kecil namun karena masuk dalam nilai mutlak maka nilai minus yang besar menjadi nilai yang paling besar. Masalah penerimaan ini juga bergantung dengan uji nilai yang untuk ditetapkan. Ada uji yang dua arah dan ada juga uji satu arah bergantung dengan kebutuhan yang dibutuhkan oleh regresi tersebut. Adapun daerah penolakan tersebut terkait dengan dua arah, Jika berada dalam jangkauan t table maka kita dapat menolak hipotesis yang menyatakan bahwa ada pengaruh pada variable tersebut. 4.2 Scatter diagram Mungkin sulit menggambarkan hubungan antara lebih dari satu variable. Kalau satu variable mungkin kita akan menyambungkan atau menghubungkan variable dengan variable independennya. Sejak awal saya kira semua variabel akan digambarkan dengan bentuk grafik 3D. Apa jadinya kalau variable tersebut lebih dari tiga, empat, lima dan bahkan enam, sulit pastinya mellihat dengan mengambarkan beberapa dimensi yang banyak sekali. Tentu saja scatter masih relevan karena itu menunjukkan hubungan antara variable independent dengan variable dependen. Analisis grafik untuk mengidentifikasi pola, trend, atau perubahan sesuai waktu untuk time series namun untuk data cross section bisa menggunakan hubungan dengan variabel lain. Scatter diagram ini adalah bagian yang penting dalam regresi berganda karena inilah yang menggambarkan hubungan antara variable independent dengan variabel dependennya. Titik-titik tersebut akan memberikan suatau gambaran atau pola dari hubungan tersebut. Setidaknya ada empat macam dari hubungan yang kita bisa perkirakan adalah sebagai berikut : 1. Tidak ada korelasi 2. Korelasi Lemah 3. Korekasi Kuat 4. Korelasi sempurna Kemudian kita akan melihat dari jenis hubungan tersebut. Inilah yang menandakan adanya hubungan atau korelasi. 1. Korelasi positif 2. Korelasi negative 3. Korelasi non linear Salah satu contoh adalah menggunakan seperti ini, Scatter bisa dilihat di sini 4.1 hpMpg &lt;- mtcars[,c(&#39;hp&#39;,&#39;mpg&#39;)] plot(x = hpMpg$hp,y = hpMpg$mpg, xlab = &quot;Horse Power&quot;, ylab = &quot;Milage&quot;, xlim = c(50,350), ylim = c(10,35), main = &quot;Horsepower vs Milage&quot; ) Figure 4.1: Grafik Scatter Horse Power dan Milage Istilah Korelasi : Hubungan anatara suatau variable dengan suatu variabel Regresi : Metode Statistik untuk mencari hubungan antara peubah bebas terhadap peubah tidak bebas Model regresi : model prediksi yang merupakan hasil regresi Outlier : data yang nilainya berbeda dari banyak data umumnya atau rata-ratanya. R kuadrat : Nilai yang menunjukkan porsi pengaruh variable independent terhadap variable dependen Adjusted R square : Nikalia R kuadrat yang sudah di sesuaikan Goodness of fit : Dalam Bahasa Indonesia keseuaian model ini menunjukkan model dari regresi yang sudah sesuai Scatter Diagram: diagram pencar adalah titik yang menghubungkan antara variabel bebas dan varaibel tidak bebas Latihan B-S Pada regresi berganda yang menjadi variable independent boleh lebih dari satu sedangkan variabel dependen hanya satu saja. B-S Pada regresi variable dependen boeh saja menggunakan variable dummy dan variable gabungan yang lainnya B-S Regresi dapat menunjukkan kekuatan dalam satu variable independent terhadap variable dependen B-S Data outlier adalah data yang berbeda dengan lainnya dan menyebabakan kerusakan dalam regresi. B-S Uji t untuk menunjukkan hubungan yang signifikan variable dependen terhadap variable independent B-S untuk melihat apakah regresi tersebut sudah baik kita dapat melihat nilai Chi Square B-S Autokorelasi bias terjadi dalam regresi linier berganda dan dapat menyebabkan kesalahan B-S Kalau kita menggunakan vairabel dummy adalah variable yang digunakan untuk membedakan antara varabel yang mempunyai kategori. B-S Nilai Adjusted R Square selalu lebih besar daripada nilai R Square karena ada tambahan berupa penyesuaian nilai banyaknya variable. Soal 1. Buatlah model dengan cara menilai kesehatan tulang untuk yang segar dengan orang yang sakit sehingga bisa mengembangkan dengan bisa membedakan yang berolahraga ataupun yang tidak? Asumsi apakah yang harus dipenuhi dalam regresi logistik coba jelaskan hal itu? Pada Altman Z Score setidaknya Z Score dibagi menjadi dua dan ada wilayah abu. saya akan gabungkan wilayah abu ke dalam wilayah yang bangkrut. Akankah ini dibenarkan ? Bagaimana cara menjelaskannya? Dalam asumsi ternyata tidak ditemukan maka yang sesuai goodnes of fit atau kebaikan model. Bagaimana mengatasi hal tersebut? Kalau di regresi logit maka iti kita lihat kalau kita melihat ada yang berbeda maka itu seperti variabel dikotomi maka akan bisa melihat misalnya dikotomi dari kesehatan jantung untuk satu dan kesehatan lainnya? Pada suatu hasil regresi ditunjukkan nilai R squarenya adalah 75%. Carilah nilai Adjusted R square model tersebut jika jumlah sample 30 dan variable bebasnya ada tiga? Carilah contoh beberapa variable independent yang mempengaruhi kepuasan pelanggan? Sebutkan beberapa kemungkinan yang ada dari regresi berganda? Apakah semakin banyak variable independent akan meningkatkan nilai R Square. Coba jelaskan jawaban anda? Apakah beda korelasi dengan regresi? 4.3 Regresi dengan Dummy Regresi dummy Kalai kita menetapkan Y sebagai variabel kategorik nitu berarti kita melakukan regresi logistik atau logit. Hanya saja ada yang masuk dalam variabel kategorik yang bisa kita gunakan untk menyelidiki hubungan kategorik dengan varoabel tertentu. Dalam regresi linear menggunakan data kategori sebagai variable independent dengan menamakan huruf satu dengan variable tertentu dan angka 0 untuk variable lainnya. Contoh perempuan yang cenderung rajin daripada laki-laki akan menghasilkan nilai yang lebih baik dari laki-laki. Tentu kasus per kasus akan berbeda dengan yang lainnya karena bisa jadi di beberapa bagian lelaki akan ada yang mempunyai prestasi lebih baik. Off course, kita bukan bicara mwngenai hal itu karena Statistik itu akan bicara banyak sample yang mewakili. Variabel kategori atau disebut dummy ini memang akan membuat sesuatu yang berbeda dengan variable yang lainnya. Variabel ini bukan masuk dalam variable angka atau kuantitaif melainkan ini adalah variable Hal itu karena antara dua kategori itu ada hal yang berbeda seperti laki-laki dan perempuan. Pemaksaan untjk mencari nilai akan membuat sesuatu menjadi terpaksa dan akan terjadi nilia residual yang sangat besar sekali dan patutu diduga model regresi akan bias tidak memenuhi BLUE. Adanya aktegori ini sedikitnya melonggarkan .dalam satu persamaan ada aetidkanya dua kategori kalau dalam satu variabel. Maka kita akan membedakan anatara laki-laki dan perempuan. Untuk memudahkan maka si peneliti akan memberikan angka 0 untuk perempuan dan angka 1 untuk laki-laki. Seperti habg kita sudaj bahasa sebelumnya jika nilai peramalan atau corecast dari perempuan hanya berupa Beta Sajam karena nilai 0 akan menihilkan angka X maupun nilai Beta yang ada dalam persamaan. Sedangkan untuk nilai laki-laki akan mendapatkan tambahan dari Beta selain nilai dari alpha tentunya. Apakah model Dummy selalau dipakai. Hal itu tentu dengan kebutuhan yang ada. Kalau terajdi perbedaan yang behitu signifikan maka kita akan menggunakan hal seperti itu tetapi kalai kita yka wlihat hal yang penting maka kita pehih baik tidak usah memakai dummy. Bagaimana anda membuat model? Membuat model bagi seorang yang pemula dan peneliti pemula adalah dengan menggunakan model yang sebelumnya. Bukan menyalin adalah sesuatu yang mudah. setidaknya dalam menggunakan model yang sudah ada karena model tersebut sudah terbukti . Kalau belum terbukti atau merancang memang akan sulit sekali dengan demikian. misalnya kita sudah pasti tdak ada perbedaan aanatara kecerdasan wanta dan laki-laki dalam ilmu bahasa maka akan sulit sekali mmenggunakan hal itu untuk membedakan anytara satu dengan yang lainnya. Hal itu menjadi percuma saja kalau kita tidak menemukan hal yang membedakan dalam model tersebut maka lebih sederhana saja kita tidak usah untuk membuat model seperti itu. Kita tinggal menggunakan regresi yang sudha biasa diguankan saja yang lebih sederhana maka itu akan lebih baik dan tidak perlu untuk membuat teori yang baru. Ketika anda bisa untuk mencari model yang membutuhkan dummy maka anda sebaiknya juga dapat mengikuti hal itu. Hal seperti ini Ketika sebuah regresi tidak memenuhi syarat kita mungkin bertanya apakah penyebabnya? Padahal kita sudah memenuhi asumsi yang sudah kita penuhi sebelumnya . Kita sudah melakukan perbaiki asumsi yang sudah ditetapkan. Permasalahan adalah bukan karena datanya. Kita sudah sepakat kalau data adalah netral. Ia seperti halnyaa bahan makanan yang segar tentu saja kalau anda memilih data yabg benar Data yang salah akan menghasilkan olahan yang salah. Sama seperti telur busuk yang akan menghasilkan kue yang dihasilkan dari telur busuk. Bagaimana rasanya? Pasti rasanya sudah tidak bagus lagi. Hal ini karena sudah buruk. Dalam membuat suatu model maka kita juga harus memperhatikan model yang sebelumnya sudah ada ini penting juga. Sebaiknya kita sudah mencontoh apa model apalagi hanya dalam tataran sekolah sarjana saja. Dengan mencontoh model bukan berarti plagaitor karena model yang sudah ada bisa menjadi rujukan bagi kita untuk menjadikan sebuah penelitian yang akan kita lakukan. Jika seorang peneliti muda maka mereka seharusnya membuat yang mirip saja atau duplikasi saja. Ketika kita memilih regresi maka kita tahu bahwa akan memeriksa hubungan antara satu faktor dengan faktor yang lainnya. Apakah ada hubungan dengan hubungan yang lain? Karena itu memang ada hubungannya dengan hubungan yang lain. Kalau tidak ada hubujgan dengan yang lain maka kita tidak bisa memeriksakannya. Kalaupun memqksakan visa jadi ada hubungan seperti yang saya jelaskan namun hubunga tersebut tidak bisa valid. Salah satu cara meyakini adalah denga literatur. LIteratur tersebut adalah landasan kita untuk membuat Kira aka. Membagi beberapa hal yang bisa kita bagikan. Dalam hal ini kita menggunakan variabel dummy atau variabel boneka. Variabel ini menggunakan angka 10 dan 0. Lalu bagaimana penetapannya? Umumnya dua angka ini untuk membedakan. Jangan kita membuat sendiri tanpa adanya pertimbangan yang matang dengan hal itu. Kita harua bisa memberikan pertimbangan yang pas bagi model yang kita bangun. Sebab namanya statistik bisa dibuat apa saja. Setelah itu kita membagi kategori itu. Berapa yang hendak kita gunakan kategori. Kalau kita hanya menggunakan dua kategori maka kita hanya membutuhkan satu data dummy saja. Kalau kita mempunyai tiga kategori maka kita setidaknya bisa untuk membuat dua variabel dummy saja. Maka kalau kita mempunyai beberapa kategori kita akan membuat dengan banyaknya kategori dikurangi satu atau variabel atau banyaknya variabel dummy = kategori - 1 Maka kita juga ahrus bijak dalam menggunakan variabel dummy tersebut karenan banyaknya akan kemungkinan membuat asusmi regresi bisa menjadi tidak terpenuhi terutama adalah masalah multikolinearitas. Maka kita harus membuatnya sesuai dengan kndis dan pemenuhan data. yang ada . Misalnya kita ingin membuat kategori pendidikan dari tiga tingkatan stratat yakni kategori bawah sarjana, kategori sarjana , dan kategori di atas sarjana maka akan dibuat dua dummy variabel. yakni Y= a + b1.X1 + b2.D1.X2 + b3.D2.X2 + e kategori satu akan saya masukkan untuk sarjana sedangkan kategori dua adalah master maka yang bukan sarjana akan masuk dalam kategori tersebut. Hasilnya kita akan bisa melihat bahwa dengan adanya data dummy tersebut maka saya bisa memprediksi ada perbedaan antra beberapa kategori tersebut. Regresi dengan "],["regresi-logistik.html", "Bab5 Regresi Logistik Glosarry Pertanyaan 5.1 Captioned figures and tables", " Bab5 Regresi Logistik Dalam regresi logisitik kita akan membuat sesuatu variabel logistik atau logit yang berbeda dengan regresi linear . Hal ini berbeda karena regresi linear biasa menggunakan variabel rasio. Untuk regresi logistik kita dapat memberikan variabel independen antara 0 atau 1 M.Hilbe (2015) Pemilihan variabel independen ini hanya dua saja biner atau (binary), misalnya antara laki dan perempuan, sakit dan sehat, sejahtera dan non sejahtera dan lain-lain. Adapun untuk variabel dependen maka hal itu dibolehkan berupa data rasio Terkadang ada juga data yang menggunakan data yang lain juga. Hal ini bergantung dengan kebutuhan penelitian yang ada. Tetapi pada beberapa kasus bisa jadi regresi yang dilakukan adalah regresi kategorik juga. Kita bisa mengembangkan model dari variabel independen yang akan kita cari prediksinya dengan beberapa faktor independen yang diduga dapat untuk mempengaruhi dari nilai variabel Y tersebut. Hal itu bisa kita lihat dalam studi mengenai regresi logistik tersebut yang ada di jurnal. Kita sambungkan teori dengan penerapan regresi logistik. Regresi logistik sebagai suatu jawaban atau respon dari keterbatasan regresi linear. Ada nilai yang sebagai variabel explanatory yang berkisar anatara pilihan nilai 1 dan juga nili 0 saja. Bagaimana interprestasi model ? Hasil regresi menghasilkan beberapa nilai yang perlu dianalisis . Nilai-nilai tersebut sama-sama seputar regresi namun karena adanya nilai dikotomi maka kita ajan sedikit berbeda untuk Apakah kita akan membedakan analisis dua data kategori tersebutnya. Tentu hal itu akan dibicarakan dan akan dijelaskan dari nilai dikotomi tersebut. Misalnya untuk regresi yang nilai angka 1 dan angka 0 maka kita harus memperhatikan kedua dikotomi tersebut. Ada hal yang membedakan karena dari awalnya memang untuk melihat pengaruh antara dua variabel kategori tersebut. Mungkinkah dari hal tersebut kita bisa memberikan interprestasi yang berbeda? Pada hubungan antara variable dependen dengan variable independen maka kita melihat nilai dari singnifikasi dari hubungan atau relasi antara variable dependen dengan variabel independennya. Kita melihat nilai p value atau Probability value. Seperti sudah menjadi kebiasaaan kalau nilai pvalue tidak boleh lebih dari 0,05 atau 5%, Kemudian melihat table ANOVA apakah nilai model sudah sesuai dengan harapan. Nilai ini menghitung kalkulasi perbedaan antara variabel dependenden maupun variabel independen. Hipotesis nol adalah tidak terjadi perbedaan yang artinya seluruh rata-rata dari nilai akan menjadi sama. Sedangkan pada hipotesis alternatif atau Ha adalah setidaknya ada satu variabel yang memiliki nilai yang berbeda. Adapun persamaan dari nilai logisitik adalah seperti ini : $ln⁡〖(p/(1-p))=β_0+β_1x 〗 $ Pada bagian variabel independen atau juga variabel bebas aka ada nilai p/(1-p) maka hal itu adalah perbandingan anatara variabel dikotomi dalam variabel independen tersebut. Misalnya kita menetapkan p itu sebagai sukses maka nilai (1-p) adalah nilai non sukses atau gagal. Contoh juka demikian kita dapat menulis kemungkinan sukses atas kemungkinan gagal. Kalau kita tetapkan kemumgkinan sukses tersebut adalah 0,7 maka kita bisa masukkan nilai sebagai berikut 0,7/(1-0,7)= 0,7/0,3 = 2,33 . hal ini berarti kita bisa artikan kalau nilai kesuksesan mempunyai peluang 2,33 kali lebih banyak daripada kegagalan. Begitu juga nilai tersebut kita bisa gunakan yang lain untuk memasukkan nilai p sebagai nilai untuk satu peluang yang sudah saya tunjuk. Perbandingan rasio antara sukses dan tidak sukse disebut juga odds. \\(p ̅=exp(β_0+β_1x )/(1+exp⁡(β_0+β_1x ) )\\) Dalam regresi logistik tidak perlu lagi untuk melakukan ujian asumsi klasik seperti yang dialkukan pada regresi linear lainnya. Hal ini mungkin dikarenakan karena sifat nilainya yang sederhana sehingga berbeda. Variabel dikotomi yang lebih sederhana membuat error mungkin tidak seberapa besar dengan regresi linear. Meski tidak menggunakan model asumsi linear akan tetapi kita tetap saja memerlukan untuk menggunakan nilai Chis Square. Hal ini penting juga untuk menilai dari regresi tersebut. Hal ini cukup sebagai tujuam uuntuk mendapatkan nilai regresi tersebut. Untuk langkah-langkah dalam regresi logistik ini kita bisa lakukan sebagai berikut : Mengumpulkan data mengenai variabel bebas maupun variabel tidak bebas dan mendapatkan seluruhnya ke dalam suatau tabulasi yang baik. Yakinkan data sudah terhitung dengan benar sesuai dengan yang hendak kita carikan. Melakukan regresi logistik menggunakan software yang sudah digunakan sebelumnya. Saya memilih menggunakan R karena lebih mudah. Memastkam nilai dari regresi itu sesuai dengan yang kita iningnkan. Nilai dari regresi terlepas dari beberapa hal seperti nlai Chi square Menginterprestasikan nilai dari regresi logistik dari perhitungan probabilitas dari hasil software. Interprestasi dari hasil regresi logistik Ketika kita sudah mendpatkan hasil regresi maka kita harus tahu untuk menerjemahkan hal ini. Dalam regresi logisitik tidak seperti regresi persamaan yang bentuknya linear. Kalau dalam regresi linear variabel bebas dapat memepengaruhi dalam besaran sekian berkat dari nilai koefisien yang ada dalam persamaan tersebut. Tetapi karena ada dua dari jenis dari variabel independen. Maksudnya ada dua kemungkinan binary atau dua peluang ketika seorang untuk memeilih nilai satu atau dua saja. Mudah seperti itu maka interprestasinya dalah seperti ini. Kalau saya mencontohkan dengan anak yang luslu maka anak yang lulus harus mempunyai syarat seperti nilai ujian yang bagus, kehadiran yang menutupi yang lain. Ketika itu kita dapat memilih peluang dari anak yang akan khusus dari nilai ujian Mata Kuliah Ujian tertentu harus memenuhi beberapa hal. Untuk yang sederhana saja kita bisa mencari hubungan perokok dengan usia yang ada. Apakah kita hubungkan anatar usia sebagai varabel bebas berhubungan dengan variabel yang kita cari. Tentu kita masih memetingkan apakah nilai signifikan dari variabel tersebut karena kalau tidak signifikan maka kita tidak bisa untuk memprediksi dari nilai tersebut. Misalnya saya akan meprediksi nilai kebangrkutan dari perusahaan dengan nilai seperti ini: \\(Log(p/(1-p) = b0 + b1*ROA\\) Nilai p adalah nilai peluang perusahaan mengalami kesulitan keuangan, b0 adalah nilai konstanta dan b1 adalah nilai koefiseien dari variabel bebasnya, dalam hal ini variabel bebasnya adalah Return on Assets (ROA). Untuk kta melakukan interprestasi adalah seperti dibawah ini. Nilai intercept atau konstanta adalah nilai yang masih ada ketika nilai ROA menjadi nol. Apakah mungkin nilia tersebut atau nilai ROA itu bisa nol. Ini mungkin saja karena ada perusahaan yang tidak menghasilkan nilai keutnungan atau nilainya menjadi nol sehingga pendapatan dari perusahaan tersebut adalah nol. Kemudian adalah nilai koefisein dari ROA ini adalah seberapa besar pengaruh jadi bukan menunjukkan kuatnya hubungan melainkan nilai besaran yang mempengaruhi rasio logit tersebut. Tentu menerjemhakan dari persamaan itu butuh berupa hasil. Katakanlah jika kemungkinan dari financial distress itu hanya 0,1 maka peluang maka ada kemungkinan kebangkrutan itu hanya sekitar 0,11 kali karena dari nilai 0,1/0,9 maka akan ada nilai yang besar sekali. Maka kita dapatkan Dalam regresi logisitik ada berapa asumsi yang bisa kita penuhi antara lain: Error harus berdistribusi normal Heterosedatisitas Hubungan variable bebas dan tidak bebas yang ternyata tidak linear Glosarry logistik logit probit Pertanyaan 1.Apa Perbedaan Regresi Liniear dan Regresi Logistik? 2.Apa definsi dari regresi logistik? 3.Apa tahapan dalam regresi logistik? Setelah mendapatkan nilai regresi logsitik maka bagaimana kita meyakinkan kalau nilai hasil regresi kita sudah terbebas dari asumsi yang buruk? 5.Apa saja yang bisa kita tafsirkan jika kita mendapatkan hasil regresi demikian? Bagiamana cara memprediksi probabilitas kejadian dari model regresi logisitik ? Jelaskan bagaimana menetapkan nilai 1 dan 0 pada variable independen tersebut? Bagiamana penerapan regresi logistik dari bidang manajemen ? 9.Apa yang dimaksud odds ratio dan mengapa itu penting? Bagiamana cara pemilihan variable dalam regresi logistic? There are two steps to cross-reference any heading: Label the heading: # Hello world {#nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, # Hello world = # Hello world {#hello-world}. To label an un-numbered heading, use: # Hello world {-#nice-label} or {# Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); If you prefer text as the link instead of a numbered reference use: any text you want can go here. 5.1 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. Don’t miss Table 5.1. knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 5.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 References "],["parts.html", "Bab6 Parts", " Bab6 Parts You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. Add a numbered part: # (PART) Act one {-} (followed by # A chapter) Add an unnumbered part: # (PART\\*) Act one {-} (followed by # A chapter) Add an appendix as a special kind of un-numbered part: # (APPENDIX) Other stuff {-} (followed by # A chapter). Chapters in an appendix are prepended with letters instead of numbers. "],["asumsi-regresi-linear.html", "Bab7 Asumsi Regresi Linear 7.1 Multikolinearitas 7.2 Autokorelasi 7.3 Heteroskedatisitas 7.4 Asumsi Normalitas 7.5 Regresi Dengan Rstudio", " Bab7 Asumsi Regresi Linear Setiap metode yang kita apakah harus kita ingat mempunyai syarat dan kondisi. Seperti kita mau membeli suatu maka kita menemukan suatau kondisi yang harus kita penuhi. Tanpa syarat dan kondisi tersebut maka kita tidak akan mendapatkan apa yang kita maui. Ada beberapa gejala kalau tidak bisa dibilang penyakit yang terdapat pada Regresi linear. Hal tersebut harus kita lewati sebagai syarat nilai peramalan dan juga koefisien determinasi dari regresi tersebut benar-benar valid. Hasil sutau persamaan regresi bisa berbeda satu sama lannya. Ini bukan terjasi kesalahan data karena Namanya data tidak pernah salah selama penegumpulany sudah benar. Adanya data yang melewati rata-rata atau outlier dapat menyebabkan hal sepErti itu. Adanya perbedaan itu maka kita harus memperbaiki terlebih dahulu asumsi. Setiap metode mmepunyai syarat begitu juga regresi harus memenuhi syarat-syarat tersebut. Ada beberapa hal yang membuat regresi tersebut tidak akan menjadi valid yang bisa kita perhatikan seperti ini: 7.1 Multikolinearitas Kita mau mencari hubungan antara variabel independen dengan variabel yang dependen, hanya saja terjadi hubungan yang baik antara variabel independen dengan variabel independen juga atau sesama variabel independen. Hubungan ini tidak bisa dibiarkan karena akan menyebabkan variabel tersebut merusak nilai perhitungan dari regresi. Hubungan sesama variabel independen dapat menyebabkan nilai R kuadrat \\((R^2)\\) begitu tinggi, namun penduga (peramalannya menjadi bias). Untuk itu hal ini harus diatasi dengan cara membuang salah satu variabel yang sama. Sebenarnya tidak terlalu sulit untuk menduga akan terjadinya multikolinearitas . Ketika kita melihat ada data tabel yang begitu mirip antara sesama variabel independen, kita harus mengecek apakah kita menyalin data yang sama untuk variabel yang berbeda. Terkadang salah satu data merupakan kelipatan dari data yang lainnya dan inilah yang menyebabkan korelasi begitu tinggi. Pastikan juga tidak ada data yang sama masuk ke dalam variabEL yang berbeda. Jika yakin ternyata data tersebut juga memang benar maka bisa jadi itu data memang mempunyai sifat yang sama. Hubungan antara korelasi keduanya sangat besar sekali hampir sampai lebih dari 80%. Kalau kita menggunakan Korelasi Pearson maka kita akan mendapatkan nilai korelasi yang tinggi. Kesalahan ini bisa jadi karena memang datanya seperti itu. Seperti harga ayam kampung dengan harga ayam ras maka kita bisa pastikan keduanya mempunyai hubungan yang positif. Kalau harga ayam ras naik maka harga ayam kampung juga naik. Meski keduanya mempunyai harga yang berbeda namun mempunyai peluang untuk naik pada waktu yang sama atau turun pada waktu yang sama. Untuk mendeteksi dari gejala ini adalah dengan melihat nilai VIF yang ada dalam software statistik. Nilai VIF yang lebih besar dari 10 maka terjadi yang namanya multikolinearitas. Kemudian ada juga nilai eugin value yang lebih dari 0,001. Untuk mengatasi multikolinearitas adalah tidak sulit. Hanya saja pilihannya adalah membuang salah satu variable dalam regresi multi variable. Hanya saja masalahnya adalah pilihan yang mana yang mau dibuang kadang ini menjadi pilihan yang dilematis. 7.2 Autokorelasi Nilai Autokorelasi terjadi ketika deret waktu mempunyai nilai galat (error) yang berkorelasi .Hal ini terjadi karena data berseri (time series) yang ada dalam suatu model. Pada beberapa kasus ternyata data cross section sendiri juga dapat mengalami autokorelasi. Pada autokorelasi terjadi karena galat yang berubah menurut waktu. Untuk menilai apakah adanya terjadinya korelasi, kita dapat menggunakan kriteria sebagai berikut yakni dl (Durbin lower) yang berarati nilai Durbin terendah atau du (Durbin upper) yang berarti nilai durbin di atas. Semua nilai yang berada di antara kedua nilai tersebut harus memenuhi syarat sehingga, model yang kita buat sudah dikatakan terbebas dari autokorelasi. Autokorelasi adalah suatu hubungan galat atau error yang berhubungan. Hubungan tersebut akan semakin membesar dan semakin mengecil pada tingkat peramalan yang dibuat oleh model yang memiliki gejala autokorelasi. Mau tidak mau nilai dari autokorelasi harus dihilangkan terlebih dahulu. Dengan kata lain kita harus membuat sesuatu model yang terbebas dari autokorelasi. Apapun regresi yang terjadi kesalahan termasuk autokrelasi karena adanya data tersebut. Karenanya pastikan terlebih dahulu data yang anda kumpulkan tersebut memang sudah benar. Setelah yakin kalau sudah melakukan regresi lagi. Untuk mendeteksi gejala ini kita mengamati pola residual terhadap urutannya atau t. Kalau data residual mempunyai pola tertentu baik meningkat maupun menurun maka patut dicurigai terjadinya autokorelasi. Kalau data tidak mempunyai pola (pattern) atau data tersebar dengan bebas maka tidak terjadi autokorelasi. Selain melakukan uji Durbin Watson kita bisa melakukan uji yang lain seperti Ljung Box uji ini juga dapat untuk menduga regresi yang kita lakukan. Uji ini akan menempatkan H0 atau Hipotesis nol adalah hasil regresi terdapat mengandung autokorelasi sedangkan hipotesis alternatif (Ha) menunjukkan kalau tidak ada autokorelasi dalam model yang diuji. Nilai Durbin Watson yang dikembangkan mempunyai rumus seperti di bawah ini: Nilai Durbin Watson yang dikembangkan mempunyai rumus seperti di bawah ini (7.1) \\[\\begin{equation} du= (∑_(t=1)^n(e_(t-1)-e_t )^2 )/(e_t^2 ) \\tag{7.1} \\end{equation}\\] Dalam uji ini ditetapkan sebagai Hipotesis nol adalah jika terjadi autokorelasi sedangkan Ha diterima jika terjadi autokorelasi H0 : ρ = 0 tidak terjadi autokrelasi Ha : ρ ≠ 0 terjadi autokorelasi Autokorelasi itu terjadi karena danya kandungan data series tetapi seperti disinggung diatas kalau data cross section pun juga menjadi autokorelasi untuk mengatasi adalah kita bisa melakukan hal seperti ini. Kita menggunakan differencing pada data time series. Setelah difference atau pembedaan ada kemungkinan data time series juga bisa diperbaiki. Salah satu mengatasi dengan menggunakan lag. Lag ini adalah konsekuensi dengan nilai dari regresi tersebut. Ada beberapa variable respon tidak selalu merespon dengan cepat. Karenanya ada sebuah respon tersebut maka aka nada repson yang terlambat sekali . Adapun bentuk antisipasi memang semuanya bervariasi karena memang tidak langsung. Bahkan kita curiga kalau suatu reaksi sudah diketahui sebelumnya berarti ada efek antisipasi oleh respon tersebut. 7.3 Heteroskedatisitas Pada mengumpulkan data, kita mungkin kurang memperhatikan adanya variance yang berbeda. Seharusnya dalam peramalan regresi juga kita harus memperhatikan asumsi bahwa error tidak berbeda E( ε ) = 0. Adanya perbedaan karena memang sulit sekali bagi regresi linear untuk mencari nilai yang paling mendekati dengan garis persamaan regresi yang mendekati dari data tersebut. Hal ini harus segera dipebaiki. Sebelum kita melihat adanya dugaan heteroskedatisitas kita harus melihat terlebih dahulu adanya potensi dari heteroskedatisitas. Kita tahu adanya variance yang berbeda anatara Y prediksi. Tentu untuk meminimalkan kita bisa menghilangkan hal tersebut. Penyebab dari terjadinya heteroskeditas adalah nilai yang ekstrim atau outlier dalam data. Maka data outlier tersebut jauh dari peramalan sedangkan kita sulit untuk membuat ramalan yang tepat. Di awal mungkin kita tidak bisa untuk menebak atau menduga apakah yang terjadi dalam regresi kita tetapi kita bisa lakukan antara lain Plot scatter antara predictor value dan residual kalau memuat grafik seperti pola topi runcing atau cone, maka akan adanya heteroskedatisitas Plot scatter antara nilai yang diprediksi dan residual kalau berbentuk seperti pola tertentu bisa jadi pola sebaran itu seperti ada garis yang mempunyai trend cenderung ke atas atau ke bawah. Ada sekumpulan garis residual yang membentuk suatu pola. Tentu hal ini tidak baik karena menunjukkan adanya pola tertentu. Breusch pagan dan white test adalah untuk mendeteksi adanya heterosskedatisitas dengan cara menghitung ?? Setelah kita mengetahui adanya gejala heteroskedatisitas maka kita harus memperbaiki hal tersebut. Ada beberapa hal namun sebelum kita memperbaiki kita harus melihat dulu mengapa terjadi heteroskedatistas Hetereoskedatisitas mengakibatkan peramalan menjdi bias membuat estimasi tidak efisien. Dalam regresi heteroskedatisitas mengakibatkan nilai t akan besar sehingga seolah terlihat nilai yang sangat signifikan. Nilai tersebut tentu tidak baik dan tidak mencerminkan nilai yang sesungguhnya. Supranto Ibarat memperbaiki Kursi Ketika kita memperbaiki suatu gejala contoh autokorelasi bisa jadi heteroskedatisitas yang tadinya belum ada akan muncul. Hal ini bisa terjadi kalau perbaikan pada kita seperti kita memukul kayu di suatu tempat maka akan ada yang terpukul di lain pihak hal itu biasa saja dalam praktik untuk membuat suatu model yang tepat . Maunya kita membetulkan satu namun tidak merusak yang lain tapi itu tidak bisa terjadi. Kalau kita mengetahui akar masalahnya maka kita akan bisa menyelesaikan masalahnya. Terkadang beberapa hal yang banyak yang sudah kita laakukan namun belum memasukkan atau belum menemukan suatu model yang sudah terbebas dari keseluruhan asumsi normal yang menjadi syarat dalam regresi sudah terbebas. Baru model tersebut dapat dikatakan menjadi estimator atau penduga yang baik. Untuk itu memang perlu kesabaran dari proses pengolahan data tersebut. Karena adalah hal yang ketentuan bisa menjadi berubah maka hal itu harus melewati revisi juga. 7.4 Asumsi Normalitas Kembali lagi ke dalam statistik dasar kalau kita tahu bahwa regresi tersebut juga memiliki data yang normal atau normalitas. Nilai residual dari peramalan tersebut terdistribusi normal. Jadi bukan datanya yang terdistribusi normal. Ketika hasil regresi linier berganda ini adalah kita akan melihat nilai residual adalah normal atau terdistribusi normal. Data yang normal adalah data yang tersebar menurut seperti lonceng tersebut. Data yang tidak tersebar normal berarti ada sesuatu yang tidak sesuai. Karenannya hasil prediksi dari data tidak normal menjadi tidak konssten. Untuk membuktikan kalau sebuah hasil residual terdistribusi normal maka kita bisa melihat dari tabel satu grafik batang yang menunjukkan sebaran yang normal. Sebaran normal seperti bentuk gunung yang simetris atau lonceng yang simetris. Baik sisi Kanan dan kiri mempunyai dua sisi yang terbagi sempurna. Kalau sudah seperti ini mska data akn tersebar normal. Pada dasarnya kita sulit sekali mendapatkan sesuatu yang normal. Terkadang dan memang seringnya muncul grafik yang tidak normal. Hal ini biasa saja karena persebaran data tersebut sering tidak normal apalagi kalau menggunakan data yang dalam jumlah terbaras. Ada kemungkinan data akan mempunyai banyak outlier yang akan menyebabkan residual malah tidak baik model permalannya Kalau ada bagian grafik yang cukup meragunakan maka kita bisa menjalankan uji Run atau Runs Test . Uji ini adalah uji non parametrik yang dapat menguji run atau giliran dari data residual tersebut. Adapun uji run mempunyai hipotesis seerti ini Ho: Data terdistribusi normal H1 : Data tidak terdistribusi normal JIka hasil uji run menunjukkan nilai peluang (probability value) lebih besar 0,05 maka hipotesis nol (Ho) diterima maka data terdistribusi normal. Sebaliknya jika nilai peluan &lt;0,05 maka ada indikasi residual data tersebut tersebar dengan tidak normal. Maka kita menolak Ho dan menerima H1. Selain run kita juga data melakukan ujia Shapiro-Wilk /(ref?)(tab:tbl-asumsi) library(knitr) ## Warning: package &#39;knitr&#39; was built under R version ## 4.3.3 dataas &lt;- data.frame( Asumsi = c(&quot;Multikolinearitas&quot;, &quot;Heteroskedatisitas&quot;, &quot;Autokorelasi&quot;, &quot;Asumsi Normal&quot;), Regresi_Linier_Sederhana = c(&quot;X&quot;, &quot;V&quot;, &quot;V&quot;, &quot;V&quot;), Regresi_Linier_Berganda = c(&quot;V&quot;, &quot;V&quot;, &quot;V&quot;, &quot;V&quot;) ) kable(dataas, caption=&quot;Perbandingan Tabel Asumsi Regresi&quot;) Table 7.1: Perbandingan Tabel Asumsi Regresi Asumsi Regresi_Linier_Sederhana Regresi_Linier_Berganda Multikolinearitas X V Heteroskedatisitas V V Autokorelasi V V Asumsi Normal V V sumber: Data Simulasi oleh penulis {#tbl-sumber} 7.5 Regresi Dengan Rstudio Salah satu cara untuk menghitung regresi adalah dengan RStudio maka kita bisa menggunakan salah sati perangkat lunak ini untuk membantu menghitung nilai persamaan regresi. secara ringkas adalah peratama menyiapkan data yang akan dilakukan analisis. Kemudian memilih beberapa package yang cocok untuk melakukan analisis ada beberapa contoh package yang dapat seperti lm yang dapat digunakan untuk menduga untuk regresi ada juga ggplot2 untuk grafik dan juga lain-lain. Ada beberapa modul yang dapat digunakan untuk melakukan regresi tersebut. A. Persiapan Sebelum melakukan regresi kita harus menentukan terlebih dahulu yang mana yang menjadi variabel yang kita regresi. KIta harus mengetahui bahwa niat regresi adalah untuk mengetahui faktor yang mepengaruhi ariabel independen terhadap faktor yang mempengaruhi variabel independen. Setelah kita melakukan sesuai dengan teori yang kita dapatkan maka kita menyiapkan data yang sudah akan kita lakukan regresi di tempat itu. Maka kita dapat menyiapkan data. Kalau data yang kita kumpulkan berupa data yang kita tabulasi dalam bentuk spreadhseet maka kita akan menyesuaikan terlebih dahulu dengan apa yang kita hendak lakukan. Karena RStudio berbeda dengan data yang ada di dalam spreadsheet atau software liannya. Kita bisa membuat penyesuaian terlebih dahulu sehingga kita bisa untuk menyelesaikan pekerjaan yang kita lakukan Memastikan data struktur yang ada Kita dapat mengimport data dengan cara menyiapak spreadsheet terlebih dahulu. Kita impor telerbih dahulu dengan seperti ini. Kita apilih file spearadsheet. dan kita akan mendpatkan data set tersebut masuk. Kita mengatur beberapa variable yang sudah kita pilih ke dalam data yang numeric atau data kuantitaif. Setelah itu baru kita set data tersebut sesuai dengan persamaan yang kita hendak cari. Sebelumnya kita tampilkan dahulu library beberapa uji yang masuk dalam regresi tersebut. Seperti melakukan uji heteroskedatisitas untuk emmastikam bahwa error karena dapat membuat estimasi menjadi tidak pas. Kemudian menguji autokorelasi dari model regresi. Hal seperti ini mutlak dilakukan Kita menjalankan regresi dan melihat apakah nilainya sudah sesuai dengan harapan. Untuk itu kita melihat apakah sudah sesuai dengan asumsi. Seperti yang ditunjukkan pada Tabel ??, konsumsi bahan bakar bervariasi berdasarkan jumlah silinder. "],["regresi-dengan-rstudio-1.html", "Bab8 Regresi Dengan Rstudio 8.1 Regresi Berganda Mtcars 8.2 Regresi Dummy 8.3 Regresi Logistic 8.4 Regresi Kuadratik 8.5 Regresi dengan menggunakan Data Panel 8.6 Regresi Mediasi dengan RStudio 8.7 Regresi dengan Moderasi", " Bab8 Regresi Dengan Rstudio Salah satu cara untuk menghitung regresi adalah dengan RStudio maka kita bisa menggunakan salah satu perangkat lunak ini untuk membantu menghitung nilai persamaan regresi. secara ringkas adalah pertama menyiapkan data yang akan dilakukan analisis. Kemudian memilih beberapa package yang cocok untuk melakukan analisis ada beberapa contoh package yang dapat seperti lm yang dapat digunakan untuk menduga untuk regresi ada juga ggplot2 untuk grafik dan juga lain-lain. Ada beberapa modul yang dapat digunakan untuk melakukan regresi tersebut. A. Persiapan Sebelum melakukan regresi kita harus menentukan terlebih dahulu yang mana yang menjadi variabel yang kita regresi. KIta harus mengetahui bahwa niat regresi adalah untuk mengetahui faktor yang mempengaruhi variabel independen terhadap faktor yang mempengaruhi variabel independen. Setelah kita melakukan sesuai dengan teori yang kita dapatkan maka kita menyiapkan data yang sudah akan kita lakukan regresi di tempat itu. Maka kita dapat menyiapkan data. Kalau data yang kita kumpulkan berupa data yang kita tabulasi dalam bentuk spreadhseet maka kita akan menyesuaikan terlebih dahulu dengan apa yang kita hendak lakukan. Karena RStudio berbeda dengan data yang ada di dalam spreadsheet atau software liannya. Kita bisa membuat penyesuaian terlebih dahulu sehingga kita bisa untuk menyelesaikan pekerjaan yang kita lakukan Memastikan data struktur yang ada Kita dapat mengimport data dengan cara menyiapak spreadsheet terlebih dahulu. Kita impor telerbih dahulu dengan seperti ini. Kita apilih file spearadsheet. dan kita akan mendpatkan data set tersebut masuk. Kita mengatur beberapa variable yang sudah kita pilih ke dalam data yang numeric atau data kuantitaif. Setelah itu baru kita set data tersebut sesuai dengan persamaan yang kita hendak cari. Sebelumnya kita tampilkan dahulu library beberapa uji yang masuk dalam regresi tersebut. Seperti melakukan uji heteroskedatisitas untuk emmastikam bahwa error karena dapat membuat estimasi menjadi tidak pas. Kemudian menguji autokorelasi dari model regresi. Hal seperti ini mutlak dilakukan Kita menjalankan regresi dan melihat apakah nilainya sudah sesuai dengan harapan. Untuk itu kita melihat apakah sudah sesuai dengan asumsi. Seperti yang ditunjukkan pada Tabel (ref?)(tab:mtcars), konsumsi bahan bakar bervariasi berdasarkan jumlah silinder. Salah satu analisis statistic yang mencari hubungan atau relasi antara satu variable dengan variable yang lain adalah regresi. Ada hubungan dua vriabel yang sifatnya dipengaruhi yakni variable dependen dan juga variabel yang mempengaruhi. Kedua variable tersebut diuji untuk mencari hubungan, Hubungan tersebut berdasarkan teori yang sudah ada. Ada suatu konstruksi yang dapat menjelaskan hubungan teori tersebut. Untuk melaksanakan regresi dengan RStudio kita bisa lakukan seperti ini : 1. Persiapan data. Kita sudah menyiapakan data yang sudah berlandaskan teori. KIat Sudha enetapkan data tersebut yang mana variable Y dan mana variable X nya. Pastikan sudah kita sudah mempunyai kecukupan data untuk regresi analisis ini . Persiapaan data dalam bentuk excel atau spreadsheet. 2. Import data dari spreadsheet ke bentuk data Rstudio. Kita akan mendapatkan data bentuk data frame dan bentuk data tibble. Jika ingin belajar mengenai data silahkan kli ke ebook saya yang lain https://andrifaisal.github.io/StatDesk/ 3. Kemudian lakukan regresi dengan fungsi LM. Kita jangan lupa masukkan package lmtest dan juga zoo 4. Uji normalitas dari hasil regresi yang kita sudah buat . Hal ini untuk memastikam kalau hasil dari regresi sudah tersebar normal dailihat dari residualsnya. 5. Uji Autokorelasi dengan menggunakan dw test. Uji ini memastikan tidak terjadinya korelasi serial atau autokorelasi pada data tersebut . 6. Uji Hetresokedtasisitas untuk melihat apakah data menunjukan ada hubungan yang terjadi anatara erros. Seharusnya error tersebut harus bernilai nol. (E(ε))=0 7. Memberikan interperestasi dari hasil regresi itu baik t test dan juga F test 8. Memberikan kesimpulan pada hasil regresi kita. Berikan kalimat pada hasil regresi yang sudah dibuat. Hal ini berkait dengan variabel mana yang mau kita teliti tersebut. 8.1 Regresi Berganda Mtcars Mencoba untuk meregresi dalam data persamaan mtcars. Sebagai variable indpenden adalah mpg sedangkan variable independent berjumlah dua yakni variable cyl dan juga variable disp. Pada kesempatan kali ini saya akan menggunakan data yang ada di rstudio yakni data set dari yang terdapat di package car. Nama datanya adalah mt cars. MT cars ini adalah satu set data yang berisi sebanyak 32 data dengan banyak sekali variabelnya namun pada kesempatan kali ini saya akan memilih dua variable independennya sakja yakni variabve yakni cyl dan disp. Kita bisa menampilkan dengan klik yang namaya mtcars maka hasilnya adalah dengan perintah View (mtcars). Sengaja tidak ditampilkan karena data ini begitu Panjang sehingga bisa memenuhi halaman dari buku. Tetapi kita bisa tampilkan di bagian depan dengan depan atau head atau tail untuk bagian bawah table. Kita bisa melihat struktur data dari mtcars seperti dibawah ini dengan mengetik mtcars. Maka akan melihat tampilan banyak dari mtcars. Kita perlu untuk melihat structure dati mtcars: str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 13 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp : num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat : num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec : num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear : num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb : num 4 4 1 1 2 1 4 2 2 4 ... ## $ hp_wt : num 288 316 216 354 602 ... ## $ log_mpg: num 3.04 3.04 3.13 3.06 2.93 ... head(mtcars) ## mpg cyl disp hp drat wt qsec vs ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 ## am gear carb hp_wt log_mpg ## Mazda RX4 1 4 4 288.20 3.044522 ## Mazda RX4 Wag 1 4 4 316.25 3.044522 ## Datsun 710 1 4 1 215.76 3.126761 ## Hornet 4 Drive 0 3 1 353.65 3.063391 ## Hornet Sportabout 0 3 2 602.00 2.928524 ## Valiant 0 3 1 363.30 2.895912 Ini adalah struktur data dari mt cars. Terlihat struktur data dari mtcars adalah data. Frame dengan 32 jumlah data (n) atau observasi (obs). Data ini terdiri dari 11 kolom yakni variable dependent satu mpg dengan 10 variabel independent lainnya. Tentu dari banyak variable ini anda bisa melakukan analisis data. Di baris pertama ada mpg yang merupakan nama variabelnya sedangkan baris selanjutanya ada kata num yang berarti itu adalah data numerik atau data angka. Sedangkan di sebelah kanan num adalah ada sejumlah angka yang menunjukkan sample dari data variable tersebut. 1. mpg adalah mile per gallon 2. cyl adalah jumlah silincer 3.disp atau dispalcement (cu.in) 4. he adalah horse power atau tenaga kuda 5, drat adalah rear axel ratio 6. wt adlah berat dalam 1000 lbs 7.qsec adalah seperempat mile 8. vs adalah bentuk mesin dimana 0 adalah V shaped dan 1 adalah straight 9. am adalah transmisi kalau 0 adalah otomatis and 1 manual 10. gear jumlah gigi depan 11. carb adalah jumlah karburator Atau kita bisa melihat dengan perintah View(mtcars) . Beginilah tampilan dari mtcars Kita bisa melihat kalau begitu banyak data variable yang ada yakni 11 dengan hanya satu variable dependen yang bernama mpg atau mile per gallon. Itu adalah jumlah mil yang ditempuh dengan satu gallon (sekitar lima liter) oleh kendaraan tersebut. Setelah kita sudah menyaipakn maka kita harus menggunakan beberapa paket yang dibutuhkan untuk pertama adalah kita menggunakan paaket lmtest atau paket zoo. Ini adalah paket yang biasa digunakan dalam analisis regresi. Kita lihat dibawah ada peringatan mengenai penggunaan paket kalau lm test harus juga mengikuti paket zoo. library(lmtest) ## Warning: package &#39;lmtest&#39; was built under R version ## 4.3.1 ## Loading required package: zoo ## Warning: package &#39;zoo&#39; was built under R version 4.3.1 ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric library(zoo) Setelah paket zoo terpasang. Maka perintahnya adalah menggunakan metode regresi sesuai dengan apa yang kita tujukan atau niatkan. Perintah dalam regresi adalah lm(variable dependent ~ variable independent 1 + Variabel independent 2, data=data) Pertama kita mengetikkan fungsi lm diikuti dengan buka kurung variable independen ada lambang seperti garis bergelombang tersebut dan diikuti dengan beberapa variable independennya. Jangan lupa dengan memasukan nama data karena ini yang akan menuju pada data yang akan kita regresi. Kalau kita lupa untuk menaruh data maka tidak akan terjadi hasil regresi tersebut.tanda sama dnegan memang jarang digunakan karena spsifik untuk meentukan parameter tertentu sebaliknya tanda yang sering digunakan adalah kurang dari dan strip (“&lt;-”) Ketika kita mengetikkan regresi tersebut dengan tanda sama dengan adalah nama regresimtcar1 adalah nama yang saya tuliskan sendiri untuk mengingat nama model saya. Nama ini memang tidak harus diingat tapi nanti kalau ini digunakan untuk melakukan beberapa perintah setelahnya. Setelah menteik perintah tersebut maka tidak ada oputput maka kita ketik perintah summary () seperti yang ada di bawah ini. Sebelum itu kita tampilkan terlebih dahulu variabel yang akan kita regresi seperti dibawah ini:?? library(knitr) kable(mtcars[, c(&quot;mpg&quot;, &quot;cyl&quot;, &quot;disp&quot;)], caption = &quot;Tabel Data Mobil&quot;) Table 8.1: Tabel Data Mobil mpg cyl disp Mazda RX4 21.0 6 160.0 Mazda RX4 Wag 21.0 6 160.0 Datsun 710 22.8 4 108.0 Hornet 4 Drive 21.4 6 258.0 Hornet Sportabout 18.7 8 360.0 Valiant 18.1 6 225.0 Duster 360 14.3 8 360.0 Merc 240D 24.4 4 146.7 Merc 230 22.8 4 140.8 Merc 280 19.2 6 167.6 Merc 280C 17.8 6 167.6 Merc 450SE 16.4 8 275.8 Merc 450SL 17.3 8 275.8 Merc 450SLC 15.2 8 275.8 Cadillac Fleetwood 10.4 8 472.0 Lincoln Continental 10.4 8 460.0 Chrysler Imperial 14.7 8 440.0 Fiat 128 32.4 4 78.7 Honda Civic 30.4 4 75.7 Toyota Corolla 33.9 4 71.1 Toyota Corona 21.5 4 120.1 Dodge Challenger 15.5 8 318.0 AMC Javelin 15.2 8 304.0 Camaro Z28 13.3 8 350.0 Pontiac Firebird 19.2 8 400.0 Fiat X1-9 27.3 4 79.0 Porsche 914-2 26.0 4 120.3 Lotus Europa 30.4 4 95.1 Ford Pantera L 15.8 8 351.0 Ferrari Dino 19.7 6 145.0 Maserati Bora 15.0 8 301.0 Volvo 142E 21.4 4 121.0 Setelah itu kita melakukan regresi dari data tersebut seperti dibawah ini regresimtcars1&lt;-lm(mpg~cyl+disp,data=mtcars) summary(regresimtcars1) ## ## Call: ## lm(formula = mpg ~ cyl + disp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.4213 -2.1722 -0.6362 1.1899 7.0516 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 34.66099 2.54700 13.609 4.02e-14 *** ## cyl -1.58728 0.71184 -2.230 0.0337 * ## disp -0.02058 0.01026 -2.007 0.0542 . ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.055 on 29 degrees of freedom ## Multiple R-squared: 0.7596, Adjusted R-squared: 0.743 ## F-statistic: 45.81 on 2 and 29 DF, p-value: 1.058e-09 Pada bagian atas kita melihat ada ringkasan Call atau perihal dari sebelumnya karena mungkin itu untuk mengingatkan agar kjita bisa untuk memastikan formula tersbeut sudah benar. Terkadang kita memang lupa untuk formula yang kita gunakan. Dibagian bawah ada yang Namanya residuals atau sisa. Ini adalah sisa dari bentuk dari model regresi dari peramalan hasil regreis tersebut terdiri dari nilai minimal yakni nilai yang palin terkecil dari nilai residuals dan juga ada nilai yang paling tinggi yakni maks. Ada juga nilai kuartil 1, kuartil 2 ( median) atau kuartil 3 yang menunjukkan pembagian residuals. Pada bagian bawah ada yang Namanya coefficients. Bagian ini adalah menjadi summary atau dari hasil regresi tersebut. Dari sini kita akan meligat ebberapa kolom yakni ; kolom pertama tanpa judul, kolom estimates, kolom standard error, nilai t (tvalue) dan nilai p (PRI&lt;tI). Pada kolom pertama ada konstantanta atau intercept. Ini adalah nilai alpha atau nilai konstanta. Ini adalah nilai yang ada meski nilai koefisein adalah nilai yang ada. Ini menjadi garis titik awal dari persaman regresi. Pada variable dari cyl dan disp terlihat ada nilai estimasi yang menunjjukan nilai koefisien dari persamaan regresi. Maka kalau ditulis persamaan dari regresi tersebut adalah sebagai berikut : Y = 34,66099 -1,58728 cyl – 0,02058 disp + e Inilah nilai yang bisa kita masukkan untuk melakukan peramalan terhadap variable dependent Y atau mpg. Pada variable cyl menunjukan p value yakni 0,337. Nilai ini adlah lebih kecil dari 0,05 maka keuputsannya adalah menolak HO dan melihat adanya pengaruh signifikan anatara variable cyl terhadap avriabel mpg. Dengan nilai -1,58728 maka menunjukkan semakin meningkatnya nilai cyl akan menurunkan mpg yakni sebesar 1,58728 satuan. Seadngkan pada variable disp yang terjdi adalah sebaliknya karena nilainya nyaris lebih kecil dari 0,05 maka 0,542 maka menunjukkan hubungan yang tidak signifkan.Artinya pengaruh tersebut tidak terlihat signifikan menurut peluang yang ada nilai peluang di bagian output model tersebut. Hasil model dari regresi ini membuktikan kalau nilai F value 29 artinya nilai derajat bebas dengan jumlah sample sebanyak 32 dan dikurangi varabel bebas (k)=2 dan juga 1. df atau v = n-k-1 = 32-2-1 =29. Dari nilai F hitung 45,81 maka hasilnya menunjukkan kalau model yang digunakan tersebut sudah sah. Dari hasil regresi kita bisa lihat kalau nilai Adjsuted R square tersebut 0,743, Artinya dua variable independedn baik cyl dan disp mempunyai pengaruh 74,3 % terhadap variable indepnden mpg. 8.1.1 Uji Normalitas Dalam melakukan uji regresi kita harus memastikan kalau data tersebut juga harus mempunyai normal.Data yang tersebar normal ini penting untuk memastikan kalau hasil regresi tersebut menjadi sah. Untuk melakukan itu kita bisa melalukan uji baik dengan test Shapiro-Wilk Normality Test atau kita juga menggunakan qqnorm atau qqline dari reisudal tersebut. Melakukan uji normalitas pada data dengan Shapiro Wilk tesy adalah dengan mengetikan perintah shapiro.test terhadap residual regresi mt cars. Dari sana terlihat output tersebut. shapiro.test(residuals(regresimtcars1)) ## ## Shapiro-Wilk normality test ## ## data: residuals(regresimtcars1) ## W = 0.9419, p-value = 0.08479 Hasil nilai dari Uji Shapiro adalah 0,9419. Dalam uji ini Nilai Ho adalah Data tersebar normal sedangkan Hipotesis Alternatif (Ha) dari uji ini adalah data tidak tersebar normal. Aturan dalam uji ini jika nilai p (P-Value) ebih besar dari 0,05 (p&gt;0,05) maka keputusan dari uji ini dalah tidak bisa menolak H_O. Artinya Data pada reiduals ini adalah tersebar dengan normal. Selain itu kita bisa melakukan dengan grafil normal qq plot. Dengan data itu kita bisa untuk melihat adanya data yang tersebar normal. Kita bisa menggunakan perintah qq normal dengan residuas. Kemudian kita bisa menambahkan qqline. Agar terlihat garis data normalitasnya. 8.1 qqnorm(residuals(regresimtcars1)) qqline(residuals(regresimtcars1)) Figure 8.1: Grafik Normalitas Dari Grafik Garis tersebut kita bisa melihat data tersebar mendekati garis lurus tersebut sehingga memang kita bsia menyimpulkan kalau regresi tersebut normal. Ada keraguan nilai residual di bagian atas sedikit menjauh dari garis lurus akan tetapi kita yakin karena sudah melakukan uji Shapiro Wilk maka data residual tersebar normal. 8.1.2 Uji Multikolinearitas Dalam analisis regresi lebih dari dua variable atau berganda maka kita harus memperhatikan adanya kemungkinan hubungan antara dua variable independen. Hubungan dua variable independent ini akan menjadi masalah bagi hasil estimasi regresi tersebut. Hasil yang ditampilkan adalah bukan hasil estimasi yang sesungguhnya tetapi hasil yang efisien. Salah satu cara untuk mencari bukti adanya multikolinearitas kita bisa emnilai nilai eugine value dan vif. Untuk menampilkan uji ini kita menggunakan library (car) kemudian kita akan mnegguakan library(car) ## Warning: package &#39;car&#39; was built under R version 4.3.1 ## Loading required package: carData ## Warning: package &#39;carData&#39; was built under R version ## 4.3.1 vif(regresimtcars1) ## cyl disp ## 5.366629 5.366629 Dalam uji Multikolinearitas terlihat kalau nilai dari VIF yakni 5,37. Nilai ini masih jauh dibawah 10 maka kita bisa membuat kesimpulamn kalau memang tidak terjadi korelasi antara variabel independen baik cyl maupun juga disp. 8.1.3 Autokorelasi Jika terjadi autokorelasi maka kita harus memperbaiki terlebih dahulu. Dalam data cross section umumnya tidak didapatkan terjadinya autokorelasi atau serial korelasi. Tetapi kita dapat menguji dengan plot atau grafik dengan melihat plot reisudals dari regreis tersebut. library(sandwich) ## Warning: package &#39;sandwich&#39; was built under R version ## 4.3.1 plot(residuals(lm(mpg ~ cyl + disp, data = mtcars))) Jika ingin memastikan lagi kita bisa menggunakan Newey Test. Dalam Newey Test kita bisa melihat apakah ada nilai yang mengandung autokorelasi dari nilai t hitungnya. Untuk menggunakan uji ini kita mengaktifkan terlebih dahulu paket (package) sandwich. Untuk itu kita bisa menggunakan perintash seperti yang dibawah ini yakni coeftest model dan juga vcov pada model. Tulisan atau syntasx perintahnya seperti dibawah ini coeftest(regresimtcars1, vcov = NeweyWest(regresimtcars1)) ## ## t test of coefficients: ## ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 34.6609947 2.2288371 15.5512 1.319e-15 *** ## cyl -1.5872768 0.3668222 -4.3271 0.0001636 *** ## disp -0.0205836 0.0071855 -2.8646 0.0076861 ** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Hasil menunjukkan kalau model regresi ini tidak terjadi autokorelasi karenanya dapat digunakan sebagai bukti kalau model regresi tidak terjadi autokorelasi. Uji Breusch Godfrey Salah satu untuk menuji autokorelasi adalah dengan menggunakan BG Test. Untuk melakukan ini kita melakukan bg test pada model yang kita sudah cari yakni regresimtcars. bgtest(regresimtcars1) ## ## Breusch-Godfrey test for serial correlation of ## order up to 1 ## ## data: regresimtcars1 ## LM test = 1.1748, df = 1, p-value = 0.2784 Uji Durbin Watson Salah satu uji yang digunakan untuk autokorelasi adalah Durbin Watson. Biasanya uji ini yang paling banyak digunakan untuk mendeteksi adanya autokorelasi. Nilai yang sering digunakan adalah nilai yang mendekati dua. Kalau nilai dw mendekati dua maka hampir bisa dikatakan tidak terjadi autokorelasi. Jika terjadi nilai dibawa dua kita masih bsia melakukan beberapa hal seperti menilai du dan dl. Kita bisa melihat di dalam table ada panduan untuk menilai adanya autokorelasi dengan cara seperti dibawah ini. dwtest(regresimtcars1) ## ## Durbin-Watson test ## ## data: regresimtcars1 ## DW = 1.5965, p-value = 0.09521 ## alternative hypothesis: true autocorrelation is greater than 0 8.1.4 Uji Heteroskedatisitas JIka kita ingin melihat variable residualsinya maka kita bisa menampilkannya speerti ini. Kita beri perintah residuals (model regresi). Residualas adalah nilai sisa selisih anatara nilai peramalan dengan nila nilai actual. Nilai residuals ini akan kita gunakan untuk menduga adanya kesalahan heteroksedatisitas. Dengan prosedur yang seperti dilakuan oleh buku Modul Probabilitas dan statistik(Reny Rian, 2018) kita akan menduga adanya heteroksedatisitas dari model dengan langkah : 1. Hitunglah nilai residuals 2. Mengkuadratkan residuals menjadi kresid 3. Kemudian ganakn taksiran fitted(regresimtcars) 4. Buatlah suatu plot yang menghubungkan kresid dan taksiran 5. Kita bisa menduga dari sini yang mana yang mengalami heteroskedatisitas. residuals(regresimtcars1) ## Mazda RX4 Mazda RX4 Wag ## -0.84395255 -0.84395255 ## Datsun 710 Hornet 4 Drive ## -3.28885510 1.57324352 ## Hornet Sportabout Valiant ## 4.14732774 -2.40601638 ## Duster 360 Merc 240D ## -0.25267226 -0.89226849 ## Merc 230 Merc 280 ## -2.61371193 -2.48751693 ## Merc 280C Merc 450SE ## -3.88751693 0.11418581 ## Merc 450SL Merc 450SLC ## 1.01418581 -1.08581419 ## Cadillac Fleetwood Lincoln Continental ## -1.84730532 -2.09430892 ## Chrysler Imperial Fiat 128 ## 1.79401841 5.70804444 ## Honda Civic Toyota Corolla ## 3.64629354 7.05160883 ## Toyota Corona Dodge Challenger ## -4.33979314 0.08281514 ## AMC Javelin Camaro Z28 ## -0.50535572 -1.45850859 ## Pontiac Firebird Fiat X1-9 ## 5.47067308 0.61421953 ## Porsche 914-2 Lotus Europa ## 0.16432359 4.04561603 ## Ford Pantera L Ferrari Dino ## 1.06207504 -2.45270705 ## Maserati Bora Volvo 142E ## -0.76710662 -4.42126787 kresid=residuals(regresimtcars1)*residuals(regresimtcars1) taksiran=fitted(regresimtcars1) plot(taksiran,kresid) Hasil menunjukkan tidak terjadi heteroskedatisitas karena tidak ada pola yang jelas antara taksiran dan juga dengan kuadrat residual. BIla ingin memastikan lagi anda bisa menggunakan beberapa uji mengenai heteroskedatisitas. Yang lain untuk memastikan adanya kehadiran heteroskedatisitas. Selain itu ada beberapa uji yang dapat anda lakukan seperti uji dibawah ini Berusch Pagan jadi uji ini yang cukup dikenal untuk mendeteksi adanya heteroskedattisitas. Dalam uji ini juga menggunakan hasil dari model regresi. Bentuk ini adalah bentuk yang paling sederhana , dalam uji ini kita menetapkan Hipotesis nol adalah menunjukkan tidak ada terjadinya heteroskedatisitas. bptest(regresimtcars1) ## ## studentized Breusch-Pagan test ## ## data: regresimtcars1 ## BP = 5.3769, df = 2, p-value = 0.06799 8.2 Regresi Dummy 8.3 Regresi Logistic Dalam Perangkat lunak Rstudio juga bisa menggunakan regresi logistik dengan seperti ini: # Load dataset data(ChickWeight) # Buat variabel target biner: berat &gt; 100 dianggap 1, sebaliknya 0 ChickWeight$weight_high &lt;- ifelse(ChickWeight$weight &gt; 100, 1, 0) # Ubah ke faktor ChickWeight$weight_high &lt;- as.factor(ChickWeight$weight_high) # Cek struktur data str(ChickWeight) ## Classes &#39;nfnGroupedData&#39;, &#39;nfGroupedData&#39;, &#39;groupedData&#39; and &#39;data.frame&#39;: 578 obs. of 5 variables: ## $ weight : num 42 51 59 64 76 93 106 125 149 171 ... ## $ Time : num 0 2 4 6 8 10 12 14 16 18 ... ## $ Chick : Ord.factor w/ 50 levels &quot;18&quot;&lt;&quot;16&quot;&lt;&quot;15&quot;&lt;..: 15 15 15 15 15 15 15 15 15 15 ... ## $ Diet : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ weight_high: Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 2 2 2 2 ... ## - attr(*, &quot;formula&quot;)=Class &#39;formula&#39; language weight ~ Time | Chick ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;outer&quot;)=Class &#39;formula&#39; language ~Diet ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;labels&quot;)=List of 2 ## ..$ x: chr &quot;Time&quot; ## ..$ y: chr &quot;Body weight&quot; ## - attr(*, &quot;units&quot;)=List of 2 ## ..$ x: chr &quot;(days)&quot; ## ..$ y: chr &quot;(gm)&quot; Kemudian kita membangun model sehingga akan kkta dapatkan seperti ini: logit_model &lt;- glm(weight_high ~ Time + Diet, data = ChickWeight, family = binomial) summary(logit_model) ## ## Call: ## glm(formula = weight_high ~ Time + Diet, family = binomial, data = ChickWeight) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -6.63367 0.60391 -10.985 &lt; 2e-16 *** ## Time 0.52388 0.04429 11.829 &lt; 2e-16 *** ## Diet2 1.08314 0.41139 2.633 0.00847 ** ## Diet3 2.24019 0.44153 5.074 3.90e-07 *** ## Diet4 2.76862 0.46120 6.003 1.94e-09 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 800.44 on 577 degrees of freedom ## Residual deviance: 299.80 on 573 degrees of freedom ## AIC: 309.8 ## ## Number of Fisher Scoring iterations: 6 Kita harus melihat terlebih dahulu apakah yang menjadi lebih baik KIta uji dengan multikolinearitasnya&gt; library(car) vif(logit_model) ## GVIF Df GVIF^(1/(2*Df)) ## Time 1.378642 1 1.174156 ## Diet 1.378642 3 1.054974 NIlai VIF masih jauh dibawah 10 artinya model ini terbebas dari multikolinearitas. # Prediksi probabilitas pred_prob &lt;- predict(logit_model, type = &quot;response&quot;) # Ubah menjadi kategori (cutoff 0.5) pred_class &lt;- ifelse(pred_prob &gt; 0.5, 1, 0) # Konversi ke faktor untuk evaluasi pred_class &lt;- as.factor(pred_class) # Confusion Matrix library(caret) ## Warning: package &#39;caret&#39; was built under R version ## 4.3.3 ## Loading required package: ggplot2 ## Warning: package &#39;ggplot2&#39; was built under R version ## 4.3.1 ## Loading required package: lattice conf_matrix &lt;- confusionMatrix(pred_class, ChickWeight$weight_high) print(conf_matrix) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 254 31 ## 1 24 269 ## ## Accuracy : 0.9048 ## 95% CI : (0.8779, 0.9275) ## No Information Rate : 0.519 ## P-Value [Acc &gt; NIR] : &lt;2e-16 ## ## Kappa : 0.8096 ## ## Mcnemar&#39;s Test P-Value : 0.4185 ## ## Sensitivity : 0.9137 ## Specificity : 0.8967 ## Pos Pred Value : 0.8912 ## Neg Pred Value : 0.9181 ## Prevalence : 0.4810 ## Detection Rate : 0.4394 ## Detection Prevalence : 0.4931 ## Balanced Accuracy : 0.9052 ## ## &#39;Positive&#39; Class : 0 ## HAsil menunjukkan test itu baik dengan nilai MC Nemar yang lebih dari 0,05 atau hasilnya sekitar o,4. pada sensisitivity dan juga Specificynya yang masing-masing sekitar 0,9 dan 0,89 berarati hanya menyisakan sedikit prosentase untuk kesalahan? 8.4 Regresi Kuadratik Ketika regresi linear yang sudah kita pelajari adalah menggambarkan suatau hubungan yang dalam bentuk garis lurus atau linear. Kini dengan adanya non linear maka hal itu masih menjadi kompleks lagi dengan hubungan yang bukan linear atau non linear. Hubungan dalam grafik antara regresi non linear akan berbeda dan bukan lagi digambarkan sebagai garis lurus akan tetapi sebagai garis yang tidak lurus. Dalam regresi kuadratik kita dihadapi dengan nilai yang berhubungan tidak bisa liner. Umumnya kudaratik membuat gerakan seperti gerakan parabola yang akan sulit dibaca dengan menggunakan garis yang linier. Memang apakah linier itu selalu hebat? ini menjadi pertanyaan sendiri. Jarang sekali model yang bentuknya kudrat dan itu memang yang sering terjadi karena memang hubungan itu mungkin hampir setara. Mungkin banyak orang yang berpikir kalau kuadrat itu memang tidak umum. Apalagi kalau sudah variable lebih dari satu, hubungan tu akan seperti pencaran yang berbeda-beda. Ada pola-pola hubungan yang tidak bisa digambarkan dengan regresi non linear sehingga tidak menghasilkan regresi linier seperti polynom, logaritmik dan eksponensial. Kalau anda bisa melihat maka anda akan lihat hubungan garis ini tidak normal. Untuk mencari adanya hubungan yang tidak linier kita dapat untuk membuat scatter diagram atau diagram pencar. Dari kumpulan titik-titik itu kita bisa menduga sebuah hubungan antara satu variable dengan variable lainnya. Seharusnya atau awalnya garis dalam hubungan variabel tersebut lurus namun ternyata tidak lurus. Tentu, tidak semua hubungan akan selalau linear dan juga bukan berarti seluruh hubungan juga non linear. Kita melihat atau mendeteksi dari perubahan apakah ada data yang terlihat berubah secara drastis? Zaman telah berubah karena begitu pesat sekali tekhnologi dnengan nama yang awalnya mesin penghitung (computer) ada yang namanya perhitungan dengan model sederhana namun kini perhitungan tersebut sudah lebih canggih lagi dari keadaan masa lampau. Kalau sekarang begitu banyak software statistik yang dapat menghitung banyak dengan cepat. karenanya dengan ilmu yang modern tersebut maka bisa untuk mencari hal yang baru dengan perhitungan yang akurat. Awalnya mungkin kita akan kesulitan untuk menentukan apakah akan terjadi regresi linear atau tidak. Mendeteksi awal Ketika kita ingin menduga suatau hubungan kita dapata melihat pola hubungan variable bebas terhadap variable tidak bebas atau dependent. Kita akan membuat suatau diagram ppencar yang menunjukkan hubungan antara kedua variable tersebut di 8.2 ggplot(trees, aes(x = Girth, y = Volume)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ poly(x, 2), color = &quot;blue&quot;) Figure 8.2: Grafik Scatter Girth Ada beberapa hubungan tidak linier dan maka kita bisa lakukan untuk hal yang seperti ini ; model_kuadrat &lt;- lm(Volume ~ Girth + I(Girth^2), data = trees) summary(model_kuadrat) ## ## Call: ## lm(formula = Volume ~ Girth + I(Girth^2), data = trees) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.4889 -2.4293 -0.3718 2.0764 7.6447 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.78627 11.22282 0.961 0.344728 ## Girth -2.09214 1.64734 -1.270 0.214534 ## I(Girth^2) 0.25454 0.05817 4.376 0.000152 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.335 on 28 degrees of freedom ## Multiple R-squared: 0.9616, Adjusted R-squared: 0.9588 ## F-statistic: 350.5 on 2 and 28 DF, p-value: &lt; 2.2e-16 Kemudian kita melihat grafiknya terlebih dahulu Kemudian kita evluasi model #multikolinearitas library(car) vif(model_kuadrat) ## Girth I(Girth^2) ## 72.09369 72.09369 #heteroskedatisitas library(lmtest) bptest(model_kuadrat) ## ## studentized Breusch-Pagan test ## ## data: model_kuadrat ## BP = 4.9159, df = 2, p-value = 0.08561 #autokorelasi dwtest(model_kuadrat) ## ## Durbin-Watson test ## ## data: model_kuadrat ## DW = 1.9245, p-value = 0.2783 ## alternative hypothesis: true autocorrelation is greater than 0 Membandingkan dengan model linier model_linear &lt;- lm(Volume ~ Girth, data = trees) anova(model_linear, model_kuadrat) ## Analysis of Variance Table ## ## Model 1: Volume ~ Girth ## Model 2: Volume ~ Girth + I(Girth^2) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 29 524.30 ## 2 28 311.38 1 212.92 19.146 0.0001524 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 8.5 Regresi dengan menggunakan Data Panel Mengelola data panel di RStudio untuk mengestimasi persamaan regresi dan mencari pengaruh variable independent terhadapa variable dependen. Salah satu metode untuk mencari pengarih variable adalah dengan data panel. Pengaruh seperti ini adalah untuk kita dapat mengestimasi daripada variable dependen. Data panel adalah data kumpulan dalam bentuk 8.5.1 Membuat Struktur Data Panel Rstudio berbeda dari perangkat lunak (software) statistik lainnya. Untuk mengelola dalam analisis appaun membutuhkan struktur data dalam bentuk rstudio. Kalau software lain cukup menyalin dan menempel (copy and paste) data spreadsheet baik itu Excel atau Google Spreadsheet dan langsung dapat untuk mengelola data namun untuk RStuido harus merubahkan dalam bentuk model data yang dikenal oleh Rstudio. Langkahnya adalah mengimpor file speadhheet dan membuat beberapa pengaturan yang relatif mudah untuk membuat data anda mudah diolah. Khusus untuk analisis panel maka yang dibutuhkan bentuk data atau struktur dari data pdata.frame yang merupakan singkatan panel data frame. Ini berbeda dengan data frame biasa di Rstudio karena ini mempertimbangkan dimensi individual dan juga dimensi waktu. Perlakukan inilah yang membuat berbeda. Disebelah kanan anda dapat mengklik import data set dan pilihlah excel. Ada beberapa pilihan lain seperti spss sas, stata, text dan lain-lain. KAlau mempunyai speadsheet maka pilihlah excel. Setelah itu anda akan mmeilih beberapa sheet. Kalau anda bekerja dalam banyak sheet di satu file maka anda harus memilih salah satu sheet. Dibawah itu anda pilih. Maka anda harus meperhatikan kerapihan dari text yang anda buat. Misalnya ada sela diantara judul table dan juga isi data maka di table yang kosong itu akan tertulis NA atau Not Available yang berarti data tidak tersedia. Menyiapkan excel sebagai data Untuk menyusun data maka yang bisa kita lakukan adalah dengan data. Karena data dnegan speadhseet kita lebih mudah. Kita bisa menyusun dengan data seperti contoh dibawah ini tobinq &lt;- read.csv2(&quot;~/jurnal/tobinq3.csv&quot;) #setelah data diupload saya akan membuat data frame khusus panel yang disebut pdata frame dengan seperti ini. jangan lupa gunakan library plm library(plm) ## Warning: package &#39;plm&#39; was built under R version 4.3.3 ptobinq=pdata.frame(tobinq,index=c(&quot;Comp&quot;,&quot;Tahun&quot;),drop.index = TRUE,row.names=TRUE) Setelah data sudah benar masuk kita dapat mengecek struktur dari data tersebut str(ptobinq) ## Classes &#39;pdata.frame&#39; and &#39;data.frame&#39;: 40 obs. of 3 variables: ## $ DAR : &#39;pseries&#39; Named num 0.49 0.44 0.42 0.4 0.4 0.49 0.44 0.42 0.4 0.4 ... ## ..- attr(*, &quot;names&quot;)= chr [1:40] &quot;Adaro-2014&quot; &quot;Adaro-2015&quot; &quot;Adaro-2016&quot; &quot;Adaro-2017&quot; ... ## ..- attr(*, &quot;index&quot;)=Classes &#39;pindex&#39; and &#39;data.frame&#39;: 40 obs. of 2 variables: ## .. ..$ Comp : Factor w/ 8 levels &quot;Adaro&quot;,&quot;ATPK&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## .. ..$ Tahun: Factor w/ 5 levels &quot;2014&quot;,&quot;2015&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... ## $ DER : &#39;pseries&#39; Named num 0.97 0.78 0.72 0.67 0.66 0.97 0.78 0.72 0.67 0.66 ... ## ..- attr(*, &quot;names&quot;)= chr [1:40] &quot;Adaro-2014&quot; &quot;Adaro-2015&quot; &quot;Adaro-2016&quot; &quot;Adaro-2017&quot; ... ## ..- attr(*, &quot;index&quot;)=Classes &#39;pindex&#39; and &#39;data.frame&#39;: 40 obs. of 2 variables: ## .. ..$ Comp : Factor w/ 8 levels &quot;Adaro&quot;,&quot;ATPK&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## .. ..$ Tahun: Factor w/ 5 levels &quot;2014&quot;,&quot;2015&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... ## $ Tobin.Q: &#39;pseries&#39; Named num -0.2702 0.2346 0.2706 0.034 0.0336 ... ## ..- attr(*, &quot;names&quot;)= chr [1:40] &quot;Adaro-2014&quot; &quot;Adaro-2015&quot; &quot;Adaro-2016&quot; &quot;Adaro-2017&quot; ... ## ..- attr(*, &quot;index&quot;)=Classes &#39;pindex&#39; and &#39;data.frame&#39;: 40 obs. of 2 variables: ## .. ..$ Comp : Factor w/ 8 levels &quot;Adaro&quot;,&quot;ATPK&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## .. ..$ Tahun: Factor w/ 5 levels &quot;2014&quot;,&quot;2015&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... ## - attr(*, &quot;index&quot;)=Classes &#39;pindex&#39; and &#39;data.frame&#39;: 40 obs. of 2 variables: ## ..$ Comp : Factor w/ 8 levels &quot;Adaro&quot;,&quot;ATPK&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## ..$ Tahun: Factor w/ 5 levels &quot;2014&quot;,&quot;2015&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... Sudah benar maka langkahnya adlah mennetukan jenis regresi data panel yang akan kita lakukan. Kemudian sesuai langkah yang sudah kita rencanakan adalah awalnya dengan melakukan regresi dari ketiga metode seperti Pooling (pooling), Fixed Effect (within) dan Random. Dalam contoh kali ini saya akan mennamakan kalau pooling adalah regplmtobinq, untuk fixed effect adalah regplmtobinq2 dan untuk random adalah regplmtobinq3. Dalam tiap perintah aka nada Namanya perintah summary yang artinya adalah menampilkan hasil regresi tersebut. #Regresi Model Pooling regplmtobinq&lt;-plm(Tobin.Q ~ DAR+DER,data=ptobinq,model=&quot;pooling&quot;) summary(regplmtobinq) ## Pooling Model ## ## Call: ## plm(formula = Tobin.Q ~ DAR + DER, data = ptobinq, model = &quot;pooling&quot;) ## ## Balanced Panel: n = 8, T = 5, N = 40 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -1.02749 -0.70659 -0.29490 0.20208 4.38311 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## (Intercept) 1.5134678 0.3209255 4.7159 3.381e-05 *** ## DAR -1.7072093 0.4715372 -3.6205 0.0008754 *** ## DER -0.0038299 0.0682864 -0.0561 0.9555757 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 62.653 ## Residual Sum of Squares: 46.235 ## R-Squared: 0.26204 ## Adj. R-Squared: 0.22215 ## F-statistic: 6.56918 on 2 and 37 DF, p-value: 0.003619 #Regresi Model Fixed regplmtobinq2&lt;-plm(Tobin.Q ~ DAR+DER,data=ptobinq,model=&quot;within&quot;) summary(regplmtobinq2) ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = Tobin.Q ~ DAR + DER, data = ptobinq, model = &quot;within&quot;) ## ## Balanced Panel: n = 8, T = 5, N = 40 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -1.196028 -0.130457 0.092081 0.186883 1.890241 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## DAR -2.400988 0.589834 -4.0706 0.0003144 *** ## DER -0.087783 0.042093 -2.0854 0.0456365 * ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 17.173 ## Residual Sum of Squares: 11.017 ## R-Squared: 0.35847 ## Adj. R-Squared: 0.16601 ## F-statistic: 8.3817 on 2 and 30 DF, p-value: 0.001283 #Regresi Model Random Effcet regplmtobinq3&lt;-plm(Tobin.Q ~ DAR+DER,data=ptobinq,model=&quot;random&quot;) summary(regplmtobinq3) ## Oneway (individual) effect Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = Tobin.Q ~ DAR + DER, data = ptobinq, model = &quot;random&quot;) ## ## Balanced Panel: n = 8, T = 5, N = 40 ## ## Effects: ## var std.dev share ## idiosyncratic 0.3672 0.6060 0.4 ## individual 0.5506 0.7420 0.6 ## theta: 0.6569 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -0.977977 -0.350254 -0.074708 0.106930 2.785480 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 1.786432 0.417645 4.2774 1.891e-05 *** ## DAR -2.087653 0.510836 -4.0867 4.375e-05 *** ## DER -0.069591 0.043000 -1.6184 0.1056 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 22.526 ## Residual Sum of Squares: 15.489 ## R-Squared: 0.31236 ## Adj. R-Squared: 0.27519 ## Chisq: 16.8073 on 2 DF, p-value: 0.00022405 8.6 Regresi Mediasi dengan RStudio Dalam regresi mediasi kita akan mencari apa faktor yang menjadi mediasi dalam suaatu hubngan. apakah hubungan itu bisa langsung (direct) atauakuah hubungan itu tidak langsung (indirect). kalau hubungan itu berupa lamgsung ditandai dengan koefisein yang besar yakni perkalian antara koefisein indeirect dengan dibandingkan koefisien yang hanya melihat hubungan yang langsung saja atau indirect Singkatnya dalam beberapa teori ada hubungan yang langsung dan tidak langsung. Kalau ada hubungan tersebut didahului oleh variabel lain. Variabel ini yang sebagai mediasi yang kita gunakanu untuk menduga suatu hubungan tersebut. Hayes (2020) Dalam regresi kita mengenal apa yang Namanya Variabel independent dan variabel tersebut yakni variabel dependent juga. Dalam mencari hubungan ini kita akhirnya hanaya menetukan mana yang paling besar. Kita harus mengikuti. Beberapa uji yang sudah kita tentukan di awal. Hal ini akan membuat kita akan melihat penagruh langsung maupun pengaruh tidak langsungnya. Adapun langkah-langkah dalam regresi mediasi adalah setidaknya dengan dua hal yakni pertama meregresi nilai X dengan nilai M. Berarti kita dalam hal ini adalah meregresi X sebagai variabel Y kita akan melihat apakah ada hubungan langsung atau tidak langsung dalam hal ini. Kalau saja kita melihat ada nilai kofeisien maka ini nanti kita akan simpan. Bagaimana kalau masalah signifikasinya. Apakah kita akan terus melihat nilai signifikan. Ataukah kita cukup melihat dari nilai koefisien saja. Bisa jadi dalam regresi yang seperti ini kita bisa melihat kalau regresi sederhana saja yang terdiri dari satu variabel bebas tidak mengalami gejala dalam regresi yang membuat nilai estimasi menjadi bias. Kalau misalnya dalam kasus terlihat kalau ada beberapa variabel yang tidak signifikan maka kita katakan efek itu tidak bisa untuk dijadikan bukti adanya efek yang dari mediasi yang kita buat. Ada juga yang menghitung dengan uji sobel. maka akan terlihat dari efek hubungan yang tidak langsung tersebut. Maka dari nilai p value dalam Uji Sobel yang ada di bawah maka kita akan bisa menyimpulkan bahwa memang ada efek mediasi dalam Pengaruh ini. # Langkah 1: Pengaruh hp terhadap wt (X -&gt; M) model_med1 &lt;- lm(wt ~ hp, data = mtcars) summary(model_med1) ## ## Call: ## lm(formula = wt ~ hp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.41757 -0.53122 -0.02038 0.42536 1.56455 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.838247 0.316520 5.808 2.39e-06 *** ## hp 0.009401 0.001960 4.796 4.15e-05 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7483 on 30 degrees of freedom ## Multiple R-squared: 0.4339, Adjusted R-squared: 0.4151 ## F-statistic: 23 on 1 and 30 DF, p-value: 4.146e-05 # Langkah 2: Pengaruh wt terhadap mpg dengan kontrol hp (M -&gt; Y dengan X sebagai kontrol) model_med2 &lt;- lm(mpg ~ hp + wt, data = mtcars) summary(model_med2) ## ## Call: ## lm(formula = mpg ~ hp + wt, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.941 -1.600 -0.182 1.050 5.854 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.22727 1.59879 23.285 &lt; 2e-16 *** ## hp -0.03177 0.00903 -3.519 0.00145 ** ## wt -3.87783 0.63273 -6.129 1.12e-06 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.593 on 29 degrees of freedom ## Multiple R-squared: 0.8268, Adjusted R-squared: 0.8148 ## F-statistic: 69.21 on 2 and 29 DF, p-value: 9.109e-12 Setelah kita menguji normalitas Kemudian kita menguji asumsi homoskedatisitas mengecek autokorelasi mengecek multikolinearitas Pada model satu terjadi heteroskedatisitas maka saya akan melaksanana solusi dengan weighted Least Square weights &lt;- 1 / fitted(model_med1)^2 # Bobot berdasarkan fitted values model_wls &lt;- lm(wt ~ hp, data = mtcars, weights = weights) summary(model_wls) ## ## Call: ## lm(formula = wt ~ hp, data = mtcars, weights = weights) ## ## Weighted Residuals: ## Min 1Q Median 3Q Max ## -0.45970 -0.15797 0.00722 0.14523 0.38062 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.565954 0.274363 5.708 3.17e-06 *** ## hp 0.011331 0.002003 5.658 3.64e-06 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2171 on 30 degrees of freedom ## Multiple R-squared: 0.5162, Adjusted R-squared: 0.5001 ## F-statistic: 32.01 on 1 and 30 DF, p-value: 3.638e-06 Kemudian saya akan menguji dengan beberapa hal seperti normalitas, heteroskedatisitas dan autkorelasi Ternyata pada dwtest tidak menujukkan hal yang menggembirakan maka kita buat dengan GLS (Generalized Least Square) dengan model ini maka dapat mengatasi OLS yang mengalami masalah Heteroskedatisitas dan juga autkorelasi. Tehnik penggunaan iterative weigted least square akan memperoleh suatu perkiraaaan parameter yang memungkinkan (maximum likehood estimation) dengan cara mentransformasi yang paling sesuai (suitable) Nelder et al. (1972) library(nlme) # Model dengan metode GLS model_gls &lt;- gls(mpg ~ hp + wt, data = mtcars, correlation = corAR1()) summary(model_gls) ## Generalized least squares fit by REML ## Model: mpg ~ hp + wt ## Data: mtcars ## AIC BIC logLik ## 161.684 168.5204 -75.84198 ## ## Correlation Structure: AR(1) ## Formula: ~1 ## Parameter estimate(s): ## Phi ## 0.3732159 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 36.72690 1.8756296 19.581107 0.0000 ## hp -0.02814 0.0086509 -3.252413 0.0029 ## wt -3.90997 0.7215335 -5.418968 0.0000 ## ## Correlation: ## (Intr) hp ## hp 0.147 ## wt -0.785 -0.664 ## ## Standardized residuals: ## Min Q1 Med Q3 ## -1.458775341 -0.602925777 -0.006730658 0.436430164 ## Max ## 2.324849808 ## ## Residual standard error: 2.656835 ## Degrees of freedom: 32 total; 29 residual normalitas shapiro.test(residuals(model_gls)) ## ## Shapiro-Wilk normality test ## ## data: residuals(model_gls) ## W = 0.92232, p-value = 0.02404 vif(model_gls) ## hp wt ## 1.789882 1.789882 8.7 Regresi dengan Moderasi Dalam satu pertanyaan apakah kita bisa untuk mencari hubungan X dengan Y saja. Seperti hubungan antara kinerja dan stress. MUngkin hal ini membuat kita binggung dengan hal ini. Kalau kita perhatikan maka kita akan melihat hubungan keda variabel terebut tetapi apakah ada yang mempengaruhi dari hal itu…? Apakah variabel dependen tersebut sama seprrti uah $X&lt;- Y &lt;- Z $ Harus pahami dari jalur tersebut Z= moderasi yang bertugas memperkuat arah hubungan tersebut. Apakah kita bisa membuat banyak variable di regresi? Dengan kata lain kita hanya menggunakan satu variable saja. \\(Y = α+ β1x1 + β.X1.X2 +ε\\) Pertanyaan Sebutkan langkah dari regresi moderasi ? Asumsi klasik apakah yang dibutuhkan ? Apa variabel moderasi? Bagaimana ditemukan variable moderasi ? Apa beda moderasei dengan intervensi ? Intervensi Dalam inetervensi kita menggunakan dummy variable sehingga model seperti ini \\(Y = α+ β1x1 +ε\\) \\(Y = α+ β1x1 + β.X1.D +ε\\) Dalam intervensi akan? Langkah -langkah dalam regresi moderasi. Adalah sebagai berikut : 1. Persiapan data . Kita mempersiapakan data yang akan kita rergresi terdiri dari variable dependen Pada bagian ini kita mengumpulkan data dan juga melakukan pembersiahan data dan meyakinkan data kita pakai sudah benar dan menghindari adanya kekosongan data. 2. Eksplorasi data : kita mendeksrisikan data yang sudah kita kumpullkan untuk memahami sifat dari data tersebut. Kemudian kita lakukan visualisasi data tersebut (apa tujuannya?) 3. Melakukan regresi Awal Sebelum kita beranjak maka kita melakukan regresi awal yang melibatkan variabel indepneden dengan variable dependend \\(Y = α+ β1x1 +ε\\) 4. Melakuan Regresi Moderasi Pada tahap kedua regresi atau tahap keempat ini melakukan regresi dengan moderasi 5. Melakukan regresi dengan factor interaksi 6. Menjalankan analysis regresi 7. Interprestasi terhadap hasil tersbeut 8. Uji Asumsi 9. Pelaporan Hasil Setelah itu kita harus memperhatikan bahwa ada beberapa asumsi yang harus dipatuhi dalam langkah regresi dengan moderasi . # Membuat variabel interaksi antara horsepower (hp) dan weight (wt) mtcars$hp_wt &lt;- mtcars$hp * mtcars$wt # Model dasar: mpg sebagai fungsi dari hp model1 &lt;- lm(mpg ~ hp, data = mtcars) summary(model1) ## ## Call: ## lm(formula = mpg ~ hp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7121 -2.1122 -0.8854 1.5819 8.2360 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 30.09886 1.63392 18.421 &lt; 2e-16 *** ## hp -0.06823 0.01012 -6.742 1.79e-07 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.863 on 30 degrees of freedom ## Multiple R-squared: 0.6024, Adjusted R-squared: 0.5892 ## F-statistic: 45.46 on 1 and 30 DF, p-value: 1.788e-07 # Model dengan moderator: mpg sebagai fungsi dari hp dan wt model2 &lt;- lm(mpg ~ hp + wt, data = mtcars) summary(model2) ## ## Call: ## lm(formula = mpg ~ hp + wt, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.941 -1.600 -0.182 1.050 5.854 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.22727 1.59879 23.285 &lt; 2e-16 *** ## hp -0.03177 0.00903 -3.519 0.00145 ** ## wt -3.87783 0.63273 -6.129 1.12e-06 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.593 on 29 degrees of freedom ## Multiple R-squared: 0.8268, Adjusted R-squared: 0.8148 ## F-statistic: 69.21 on 2 and 29 DF, p-value: 9.109e-12 # Model dengan interaksi: mpg sebagai fungsi dari hp, wt, dan interaksi hp*wt model3 &lt;- lm(mpg ~ hp * wt, data = mtcars) summary(model3) ## ## Call: ## lm(formula = mpg ~ hp * wt, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.0632 -1.6491 -0.7362 1.4211 4.5513 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 49.80842 3.60516 13.816 5.01e-14 *** ## hp -0.12010 0.02470 -4.863 4.04e-05 *** ## wt -8.21662 1.26971 -6.471 5.20e-07 *** ## hp:wt 0.02785 0.00742 3.753 0.000811 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.153 on 28 degrees of freedom ## Multiple R-squared: 0.8848, Adjusted R-squared: 0.8724 ## F-statistic: 71.66 on 3 and 28 DF, p-value: 2.981e-13 # Menghitung residual dari model residuals_model &lt;- residuals(model3) # Plot Q-Q qqnorm(residuals_model) qqline(residuals_model, col = &quot;red&quot;) # Shapiro-Wilk test shapiro.test(residuals_model) ## ## Shapiro-Wilk normality test ## ## data: residuals_model ## W = 0.95447, p-value = 0.1928 # Plot residual vs fitted values plot(fitted(model3), residuals_model) abline(h = 0, col = &quot;red&quot;) # Uji Breusch-Pagan library(lmtest) bptest(model3) ## ## studentized Breusch-Pagan test ## ## data: model3 ## BP = 8.4646, df = 3, p-value = 0.03732 # Plot residual vs variabel independen hp plot(mtcars$hp, residuals_model) abline(h = 0, col = &quot;red&quot;) # Plot residual vs variabel independen wt plot(mtcars$wt, residuals_model) abline(h = 0, col = &quot;red&quot;) # Uji Durbin-Watson dwtest(model3) ## ## Durbin-Watson test ## ## data: model3 ## DW = 2.1275, p-value = 0.5339 ## alternative hypothesis: true autocorrelation is greater than 0 #mengatasi heteroskedatisitas # Transformasi logaritma pada variabel dependen mtcars$log_mpg &lt;- log(mtcars$mpg) # Model regresi dengan variabel dependen yang telah ditransformasi model_trans &lt;- lm(log_mpg ~ hp * wt, data = mtcars) summary(model_trans) ## ## Call: ## lm(formula = log_mpg ~ hp * wt, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.15996 -0.08028 -0.01847 0.07809 0.21127 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.1117239 0.1809761 22.720 &lt; 2e-16 *** ## hp -0.0035277 0.0012398 -2.845 0.00821 ** ## wt -0.2980027 0.0637384 -4.675 6.73e-05 *** ## hp:wt 0.0006256 0.0003725 1.680 0.10416 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1081 on 28 degrees of freedom ## Multiple R-squared: 0.881, Adjusted R-squared: 0.8683 ## F-statistic: 69.12 on 3 and 28 DF, p-value: 4.645e-13 # Uji Breusch-Pagan pada model baru bptest(model_trans) ## ## studentized Breusch-Pagan test ## ## data: model_trans ## BP = 12.552, df = 3, p-value = 0.005712 # Menghitung bobot sebagai invers dari residuals kuadrat weights &lt;- 1 / fitted(lm(abs(residuals_model) ~ model3$fitted.values))^2 # Model WLS model_wls &lt;- lm(mpg ~ hp * wt, data = mtcars, weights = weights) summary(model_wls) ## ## Call: ## lm(formula = mpg ~ hp * wt, data = mtcars, weights = weights) ## ## Weighted Residuals: ## Min 1Q Median 3Q Max ## -1.6900 -0.9623 -0.3676 0.8809 2.2809 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.045973 4.208430 11.892 1.84e-12 *** ## hp -0.118753 0.024265 -4.894 3.70e-05 *** ## wt -8.385811 1.392445 -6.022 1.72e-06 *** ## hp:wt 0.028064 0.007355 3.816 0.000687 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.209 on 28 degrees of freedom ## Multiple R-squared: 0.8751, Adjusted R-squared: 0.8617 ## F-statistic: 65.4 on 3 and 28 DF, p-value: 9.141e-13 # Uji Breusch-Pagan pada model WLS bptest(model_wls) ## ## studentized Breusch-Pagan test ## ## data: model_wls ## BP = 3.3157, df = 3, p-value = 0.3455 library(sandwich) library(lmtest) # Model awal dengan robust standard errors coeftest(model3, vcov = vcovHC(model3, type = &quot;HC1&quot;)) ## ## t test of coefficients: ## ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 49.8084234 4.3915285 11.3419 5.569e-12 *** ## hp -0.1201021 0.0264559 -4.5397 9.752e-05 *** ## wt -8.2166243 1.4177290 -5.7956 3.176e-06 *** ## hp:wt 0.0278481 0.0079435 3.5058 0.001553 ** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
